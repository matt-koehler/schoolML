{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team_1_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnlU90_INcxr"
      },
      "source": [
        "Team 1 Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0rXG-UnOR0o"
      },
      "source": [
        "## Merging Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZPZdcz1M-Zs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf39f28f-bfad-443e-d832-5beace297bad"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-UtSqijtoEe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d601fa02-1964-4120-b1d3-d5099eb99bfc"
      },
      "source": [
        "#loading datasets\n",
        "grad18 = pd.read_csv('/content/gdrive/My Drive/CS4774_Project/newgrad18.csv') #gradrate for each school, 2017-2018\n",
        "test18 = pd.read_csv('/content/gdrive/My Drive/CS4774_Project/newtest19.csv') #unused\n",
        "food19 = pd.read_csv('/content/gdrive/My Drive/CS4774_Project/fixfixl.csv') #free reduced lunch 2018-2019 -> 2017-2018 dataset is formatted poorly and hard to use ->fixed 2017-2018 to be workable\n",
        "                                                                              \n",
        "#acc19 = pd.read_csv('/content/gdrive/My Drive/CS4774_Project/acc19.csv')\n",
        "#cohort_20 = pd.read_csv('/content/gdrive/My Drive/CS4774_Project/cohort2020.csv')\n",
        "advclass18 = pd.read_csv('/content/gdrive/My Drive/CS4774_Project/advclass18.csv') #advanced classes 2017-2018\n",
        "studentcount18 = pd.read_csv('/content/gdrive/My Drive/CS4774_Project/studentcount.csv') #student count 2017-2018\n",
        "suspensiondays18 = pd.read_csv('/content/gdrive/My Drive/CS4774_Project/fixsusp.csv') #suspension 2017-2018??????\n",
        "\n",
        "suspensiondays18.info()\n",
        "food19['School Number'] = food19['School Number'].fillna(0).astype(int)\n",
        "#food19['FR%'] = food19['FR%'].astype(float)\n",
        "grad18['School Name'] = grad18['School Name'].str.upper()\n",
        "\n",
        "\n",
        "#merging datasets\n",
        "comb = pd.merge(grad18,food19, left_on=['School Number','Division Number'], right_on = ['School Number', 'Division Number'], how='left')\n",
        "\n",
        "advclass18['School Name'] = advclass18['School Name'].str.upper()\n",
        "studentcount18['School Name'] = studentcount18['School Name'].str.upper()\n",
        "\n",
        "comb1 = pd.merge(comb,advclass18, left_on=['School Name_x','Division Name'], right_on = ['School Name', 'Division Name'], how='left')\n",
        "\n",
        "comb1 = comb1.drop(columns=['School Name_x'])\n",
        "comb2 = pd.merge(comb1,studentcount18, left_on=['School Name','Division Name'], right_on = ['School Name', 'Division Name'], how='left')\n",
        "\n",
        "comb2['Governor\\'s School Enrollment'] = comb2['Governor\\'s School Enrollment'].astype(float, errors = 'raise')\n",
        "comb2['Governor\\'s STEM Academy'] = comb2['Governor\\'s STEM Academy'].astype(float, errors = 'raise')\n",
        "comb2['Governor\\'s Health Academy'] = comb2['Governor\\'s Health Academy'].astype(float, errors = 'raise')\n",
        "comb2['Seniors Awarded IB Diplomas'] = comb2['Seniors Awarded IB Diplomas'].astype(float, errors = 'raise')\n",
        "comb2['Senior IB Enrollment'] = comb2['Senior IB Enrollment'].astype(float, errors = 'raise')\n",
        "comb2['Students taking 1 or more AP Courses'] = comb2['Students taking 1 or more AP Courses'].astype(float, errors = 'raise')\n",
        "comb2['Students taking 1 or more AP Exams'] = comb2['Students taking 1 or more AP Exams'].astype(float, errors = 'raise')\n",
        "comb2['Students taking 1 or more Dual Enrollment Courses 1'] = comb2['Students taking 1 or more Dual Enrollment Courses 1'].astype(float, errors = 'raise')\n",
        "\n",
        "suspensiondays18['School Name'] = suspensiondays18['School Name'].str.upper()\n",
        "\n",
        "comb3 = pd.merge(comb2,suspensiondays18, left_on=['School Name','Division Name'], right_on = ['School Name', 'Division Name'], how='left')\n",
        "comb3.info()\n",
        "comb3.head(50)\n",
        "#grad18.info()\n",
        "#grad18.head(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1982 entries, 0 to 1981\n",
            "Data columns (total 5 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   School Name       1982 non-null   object\n",
            " 1   TOT_DAYSMISSED_M  1982 non-null   int64 \n",
            " 2   TOT_DAYSMISSED_F  1982 non-null   int64 \n",
            " 3   nn                1982 non-null   object\n",
            " 4   Division Name     1982 non-null   object\n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 77.5+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 332 entries, 0 to 331\n",
            "Data columns (total 45 columns):\n",
            " #   Column                                               Non-Null Count  Dtype  \n",
            "---  ------                                               --------------  -----  \n",
            " 0   Cohort Year                                          332 non-null    int64  \n",
            " 1   Division Number_x                                    332 non-null    int64  \n",
            " 2   Division Name                                        332 non-null    object \n",
            " 3   School Number_x                                      332 non-null    int64  \n",
            " 4   Type of Graduation Rate                              332 non-null    object \n",
            " 5   Rate Type                                            332 non-null    object \n",
            " 6   Graduation Rate                                      332 non-null    object \n",
            " 7   GradRate                                             332 non-null    object \n",
            " 8   GrRa                                                 324 non-null    float64\n",
            " 9   DN                                                   330 non-null    object \n",
            " 10  notnumber                                            330 non-null    object \n",
            " 11  School Name_y                                        330 non-null    object \n",
            " 12  School Type                                          330 non-null    object \n",
            " 13  Low Grade                                            330 non-null    object \n",
            " 14  High Grade                                           330 non-null    object \n",
            " 15  SNP Memb                                             329 non-null    object \n",
            " 16  FREE Elig.                                           329 non-null    object \n",
            " 17  FREE %                                               329 non-null    object \n",
            " 18  RED Elig.                                            329 non-null    object \n",
            " 19  RED %                                                329 non-null    object \n",
            " 20  TOTAL F/R Elig.                                      329 non-null    object \n",
            " 21  TOTAL F/R %                                          329 non-null    object \n",
            " 22  FR                                                   329 non-null    object \n",
            " 23  FR%                                                  329 non-null    float64\n",
            " 24  Division Number_y                                    330 non-null    object \n",
            " 25  School Number_y                                      330 non-null    float64\n",
            " 26  School Name                                          330 non-null    object \n",
            " 27  Governor's School Enrollment                         330 non-null    float64\n",
            " 28  Governor's STEM Academy                              330 non-null    float64\n",
            " 29  Governor's Health Academy                            330 non-null    float64\n",
            " 30  Seniors Awarded IB Diplomas                          330 non-null    float64\n",
            " 31  Senior IB Enrollment                                 330 non-null    float64\n",
            " 32  Students taking 1 or more AP Courses                 330 non-null    float64\n",
            " 33  Students taking 1 or more AP Exams                   330 non-null    float64\n",
            " 34  Students taking 1 or more Dual Enrollment Courses 1  330 non-null    float64\n",
            " 35  School Year                                          327 non-null    object \n",
            " 36  Division Number                                      327 non-null    float64\n",
            " 37  School Number                                        327 non-null    float64\n",
            " 38  Full Time Count (All Grades)                         327 non-null    object \n",
            " 39  Part Time Count (All Grades)                         327 non-null    object \n",
            " 40  Total Count                                          327 non-null    object \n",
            " 41  Student Count                                        327 non-null    float64\n",
            " 42  TOT_DAYSMISSED_M                                     319 non-null    float64\n",
            " 43  TOT_DAYSMISSED_F                                     319 non-null    float64\n",
            " 44  nn                                                   319 non-null    object \n",
            "dtypes: float64(16), int64(3), object(26)\n",
            "memory usage: 119.3+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cohort Year</th>\n",
              "      <th>Division Number_x</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>School Number_x</th>\n",
              "      <th>Type of Graduation Rate</th>\n",
              "      <th>Rate Type</th>\n",
              "      <th>Graduation Rate</th>\n",
              "      <th>GradRate</th>\n",
              "      <th>GrRa</th>\n",
              "      <th>DN</th>\n",
              "      <th>notnumber</th>\n",
              "      <th>School Name_y</th>\n",
              "      <th>School Type</th>\n",
              "      <th>Low Grade</th>\n",
              "      <th>High Grade</th>\n",
              "      <th>SNP Memb</th>\n",
              "      <th>FREE Elig.</th>\n",
              "      <th>FREE %</th>\n",
              "      <th>RED Elig.</th>\n",
              "      <th>RED %</th>\n",
              "      <th>TOTAL F/R Elig.</th>\n",
              "      <th>TOTAL F/R %</th>\n",
              "      <th>FR</th>\n",
              "      <th>FR%</th>\n",
              "      <th>Division Number_y</th>\n",
              "      <th>School Number_y</th>\n",
              "      <th>School Name</th>\n",
              "      <th>Governor's School Enrollment</th>\n",
              "      <th>Governor's STEM Academy</th>\n",
              "      <th>Governor's Health Academy</th>\n",
              "      <th>Seniors Awarded IB Diplomas</th>\n",
              "      <th>Senior IB Enrollment</th>\n",
              "      <th>Students taking 1 or more AP Courses</th>\n",
              "      <th>Students taking 1 or more AP Exams</th>\n",
              "      <th>Students taking 1 or more Dual Enrollment Courses 1</th>\n",
              "      <th>School Year</th>\n",
              "      <th>Division Number</th>\n",
              "      <th>School Number</th>\n",
              "      <th>Full Time Count (All Grades)</th>\n",
              "      <th>Part Time Count (All Grades)</th>\n",
              "      <th>Total Count</th>\n",
              "      <th>Student Count</th>\n",
              "      <th>TOT_DAYSMISSED_M</th>\n",
              "      <th>TOT_DAYSMISSED_F</th>\n",
              "      <th>nn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>Accomack County</td>\n",
              "      <td>540</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>82.47%</td>\n",
              "      <td>82.47</td>\n",
              "      <td>82.47</td>\n",
              "      <td>1</td>\n",
              "      <td>540</td>\n",
              "      <td>ARCADIA HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>657</td>\n",
              "      <td>364</td>\n",
              "      <td>55.40%</td>\n",
              "      <td>56</td>\n",
              "      <td>8.52%</td>\n",
              "      <td>420</td>\n",
              "      <td>63.93%</td>\n",
              "      <td>63.93</td>\n",
              "      <td>63.93</td>\n",
              "      <td>1</td>\n",
              "      <td>540.0</td>\n",
              "      <td>ARCADIA HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>1.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>622</td>\n",
              "      <td></td>\n",
              "      <td>622</td>\n",
              "      <td>622.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>ACCOMACK County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>Accomack County</td>\n",
              "      <td>580</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>100.00%</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>1</td>\n",
              "      <td>580</td>\n",
              "      <td>CHINCOTEAGUE HIGH</td>\n",
              "      <td>Combined</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>292</td>\n",
              "      <td>96</td>\n",
              "      <td>32.88%</td>\n",
              "      <td>9</td>\n",
              "      <td>3.08%</td>\n",
              "      <td>105</td>\n",
              "      <td>35.96%</td>\n",
              "      <td>35.96</td>\n",
              "      <td>35.96</td>\n",
              "      <td>1</td>\n",
              "      <td>580.0</td>\n",
              "      <td>CHINCOTEAGUE HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>1.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>286</td>\n",
              "      <td></td>\n",
              "      <td>286</td>\n",
              "      <td>286.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>ACCOMACK County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>Accomack County</td>\n",
              "      <td>70</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>85.56%</td>\n",
              "      <td>85.56</td>\n",
              "      <td>85.56</td>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "      <td>NANDUA HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>783</td>\n",
              "      <td>364</td>\n",
              "      <td>46.49%</td>\n",
              "      <td>39</td>\n",
              "      <td>4.98%</td>\n",
              "      <td>403</td>\n",
              "      <td>51.47%</td>\n",
              "      <td>51.47</td>\n",
              "      <td>51.47</td>\n",
              "      <td>1</td>\n",
              "      <td>70.0</td>\n",
              "      <td>NANDUA HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>739</td>\n",
              "      <td>1</td>\n",
              "      <td>740</td>\n",
              "      <td>740.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>ACCOMACK County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>Accomack County</td>\n",
              "      <td>530</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>&lt;</td>\n",
              "      <td>&lt;</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>530</td>\n",
              "      <td>TANGIER COMBINED</td>\n",
              "      <td>Combined</td>\n",
              "      <td>Pre-K</td>\n",
              "      <td>12</td>\n",
              "      <td>62</td>\n",
              "      <td>22</td>\n",
              "      <td>35.48%</td>\n",
              "      <td>2</td>\n",
              "      <td>3.23%</td>\n",
              "      <td>24</td>\n",
              "      <td>38.71%</td>\n",
              "      <td>38.71</td>\n",
              "      <td>38.71</td>\n",
              "      <td>1</td>\n",
              "      <td>530.0</td>\n",
              "      <td>TANGIER COMBINED</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>1.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>60</td>\n",
              "      <td></td>\n",
              "      <td>60</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ACCOMACK County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018</td>\n",
              "      <td>2</td>\n",
              "      <td>Albemarle County</td>\n",
              "      <td>880</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>94.06%</td>\n",
              "      <td>94.06</td>\n",
              "      <td>94.06</td>\n",
              "      <td>2</td>\n",
              "      <td>880</td>\n",
              "      <td>ALBEMARLE HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1,954</td>\n",
              "      <td>487</td>\n",
              "      <td>24.92%</td>\n",
              "      <td>84</td>\n",
              "      <td>4.30%</td>\n",
              "      <td>571</td>\n",
              "      <td>29.22%</td>\n",
              "      <td>29.22</td>\n",
              "      <td>29.22</td>\n",
              "      <td>2</td>\n",
              "      <td>880.0</td>\n",
              "      <td>ALBEMARLE HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>448.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>2.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>1,992</td>\n",
              "      <td>5</td>\n",
              "      <td>1,997</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>419.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>ALBEMARLE County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2018</td>\n",
              "      <td>2</td>\n",
              "      <td>Albemarle County</td>\n",
              "      <td>1052</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>87.46%</td>\n",
              "      <td>87.46</td>\n",
              "      <td>87.46</td>\n",
              "      <td>2</td>\n",
              "      <td>1052</td>\n",
              "      <td>MONTICELLO HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1,131</td>\n",
              "      <td>330</td>\n",
              "      <td>29.18%</td>\n",
              "      <td>47</td>\n",
              "      <td>4.16%</td>\n",
              "      <td>377</td>\n",
              "      <td>33.33%</td>\n",
              "      <td>33.33</td>\n",
              "      <td>33.33</td>\n",
              "      <td>2</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>MONTICELLO HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>283.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>1,130</td>\n",
              "      <td>3</td>\n",
              "      <td>1,133</td>\n",
              "      <td>1133.0</td>\n",
              "      <td>293.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>ALBEMARLE County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2018</td>\n",
              "      <td>2</td>\n",
              "      <td>Albemarle County</td>\n",
              "      <td>890</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>72.22%</td>\n",
              "      <td>72.22</td>\n",
              "      <td>72.22</td>\n",
              "      <td>2</td>\n",
              "      <td>890</td>\n",
              "      <td>MURRAY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>99</td>\n",
              "      <td>20</td>\n",
              "      <td>20.20%</td>\n",
              "      <td>4</td>\n",
              "      <td>4.04%</td>\n",
              "      <td>24</td>\n",
              "      <td>24.24%</td>\n",
              "      <td>24.24</td>\n",
              "      <td>24.24</td>\n",
              "      <td>2</td>\n",
              "      <td>890.0</td>\n",
              "      <td>MURRAY HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>2.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>100</td>\n",
              "      <td></td>\n",
              "      <td>100</td>\n",
              "      <td>100.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>ALBEMARLE County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2018</td>\n",
              "      <td>2</td>\n",
              "      <td>Albemarle County</td>\n",
              "      <td>140</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>98.25%</td>\n",
              "      <td>98.25</td>\n",
              "      <td>98.25</td>\n",
              "      <td>2</td>\n",
              "      <td>140</td>\n",
              "      <td>WESTERN ALBEMARLE HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1,135</td>\n",
              "      <td>97</td>\n",
              "      <td>8.55%</td>\n",
              "      <td>30</td>\n",
              "      <td>2.64%</td>\n",
              "      <td>127</td>\n",
              "      <td>11.19%</td>\n",
              "      <td>11.19</td>\n",
              "      <td>11.19</td>\n",
              "      <td>2</td>\n",
              "      <td>140.0</td>\n",
              "      <td>WESTERN ALBEMARLE HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>502.0</td>\n",
              "      <td>417.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>2.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>1,139</td>\n",
              "      <td></td>\n",
              "      <td>1,139</td>\n",
              "      <td>1139.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>ALBEMARLE County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2018</td>\n",
              "      <td>101</td>\n",
              "      <td>Alexandria City</td>\n",
              "      <td>210</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>80.64%</td>\n",
              "      <td>80.64</td>\n",
              "      <td>80.64</td>\n",
              "      <td>101</td>\n",
              "      <td>210</td>\n",
              "      <td>TC WILLIAMS HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>3,014</td>\n",
              "      <td>1,381</td>\n",
              "      <td>45.82%</td>\n",
              "      <td>297</td>\n",
              "      <td>9.85%</td>\n",
              "      <td>1,678</td>\n",
              "      <td>55.67%</td>\n",
              "      <td>55.67</td>\n",
              "      <td>55.67</td>\n",
              "      <td>101</td>\n",
              "      <td>210.0</td>\n",
              "      <td>T.C. WILLIAMS HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>976.0</td>\n",
              "      <td>976.0</td>\n",
              "      <td>414.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>101.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>3,963</td>\n",
              "      <td>11</td>\n",
              "      <td>3,974</td>\n",
              "      <td>3974.0</td>\n",
              "      <td>967.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>ALEXANDRIA City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2018</td>\n",
              "      <td>3</td>\n",
              "      <td>Alleghany County</td>\n",
              "      <td>310</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>93.63%</td>\n",
              "      <td>93.63</td>\n",
              "      <td>93.63</td>\n",
              "      <td>3</td>\n",
              "      <td>310</td>\n",
              "      <td>ALLEGHANY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>723</td>\n",
              "      <td>241</td>\n",
              "      <td>33.33%</td>\n",
              "      <td>57</td>\n",
              "      <td>7.88%</td>\n",
              "      <td>298</td>\n",
              "      <td>41.22%</td>\n",
              "      <td>41.22</td>\n",
              "      <td>41.22</td>\n",
              "      <td>3</td>\n",
              "      <td>310.0</td>\n",
              "      <td>ALLEGHANY HIGH</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>3.0</td>\n",
              "      <td>310.0</td>\n",
              "      <td>729</td>\n",
              "      <td></td>\n",
              "      <td>729</td>\n",
              "      <td>729.0</td>\n",
              "      <td>1043.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>ALLEGHANY County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2018</td>\n",
              "      <td>4</td>\n",
              "      <td>Amelia County</td>\n",
              "      <td>10</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>90.30%</td>\n",
              "      <td>90.30</td>\n",
              "      <td>90.30</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>AMELIA COUNTY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>551</td>\n",
              "      <td>198</td>\n",
              "      <td>35.93%</td>\n",
              "      <td>29</td>\n",
              "      <td>5.26%</td>\n",
              "      <td>227</td>\n",
              "      <td>41.20%</td>\n",
              "      <td>41.20</td>\n",
              "      <td>41.20</td>\n",
              "      <td>4</td>\n",
              "      <td>10.0</td>\n",
              "      <td>AMELIA COUNTY HIGH</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>547</td>\n",
              "      <td></td>\n",
              "      <td>547</td>\n",
              "      <td>547.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>AMELIA County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2018</td>\n",
              "      <td>5</td>\n",
              "      <td>Amherst County</td>\n",
              "      <td>750</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>93.25%</td>\n",
              "      <td>93.25</td>\n",
              "      <td>93.25</td>\n",
              "      <td>5</td>\n",
              "      <td>750</td>\n",
              "      <td>AMHERST COUNTY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>U</td>\n",
              "      <td>12</td>\n",
              "      <td>1,160</td>\n",
              "      <td>415</td>\n",
              "      <td>35.78%</td>\n",
              "      <td>89</td>\n",
              "      <td>7.67%</td>\n",
              "      <td>504</td>\n",
              "      <td>43.45%</td>\n",
              "      <td>43.45</td>\n",
              "      <td>43.45</td>\n",
              "      <td>5</td>\n",
              "      <td>750.0</td>\n",
              "      <td>AMHERST COUNTY HIGH</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>5.0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>1,183</td>\n",
              "      <td></td>\n",
              "      <td>1,183</td>\n",
              "      <td>1183.0</td>\n",
              "      <td>2809.0</td>\n",
              "      <td>3914.0</td>\n",
              "      <td>AMHERST County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2018</td>\n",
              "      <td>6</td>\n",
              "      <td>Appomattox County</td>\n",
              "      <td>260</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>93.81%</td>\n",
              "      <td>93.81</td>\n",
              "      <td>93.81</td>\n",
              "      <td>6</td>\n",
              "      <td>260</td>\n",
              "      <td>APPOMATTOX COUNTY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>694</td>\n",
              "      <td>271</td>\n",
              "      <td>39.05%</td>\n",
              "      <td>34</td>\n",
              "      <td>4.90%</td>\n",
              "      <td>305</td>\n",
              "      <td>43.95%</td>\n",
              "      <td>43.95</td>\n",
              "      <td>43.95</td>\n",
              "      <td>6</td>\n",
              "      <td>260.0</td>\n",
              "      <td>APPOMATTOX COUNTY HIGH</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>6.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>700</td>\n",
              "      <td></td>\n",
              "      <td>700</td>\n",
              "      <td>700.0</td>\n",
              "      <td>574.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>APPOMATTOX County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>Arlington County</td>\n",
              "      <td>618</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>40.54%</td>\n",
              "      <td>40.54</td>\n",
              "      <td>40.54</td>\n",
              "      <td>7</td>\n",
              "      <td>618</td>\n",
              "      <td>ARLINGTON COMMUNITY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>255</td>\n",
              "      <td>72</td>\n",
              "      <td>28.24%</td>\n",
              "      <td>33</td>\n",
              "      <td>12.94%</td>\n",
              "      <td>105</td>\n",
              "      <td>41.18%</td>\n",
              "      <td>41.18</td>\n",
              "      <td>41.18</td>\n",
              "      <td>7</td>\n",
              "      <td>618.0</td>\n",
              "      <td>ARLINGTON COMMUNITY HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>7.0</td>\n",
              "      <td>618.0</td>\n",
              "      <td>168</td>\n",
              "      <td></td>\n",
              "      <td>168</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ARLINGTON County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>Arlington County</td>\n",
              "      <td>450</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>91.00%</td>\n",
              "      <td>91.00</td>\n",
              "      <td>91.00</td>\n",
              "      <td>7</td>\n",
              "      <td>450</td>\n",
              "      <td>WAKEFIELD HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>2,598</td>\n",
              "      <td>758</td>\n",
              "      <td>29.18%</td>\n",
              "      <td>249</td>\n",
              "      <td>9.58%</td>\n",
              "      <td>1,007</td>\n",
              "      <td>38.76%</td>\n",
              "      <td>38.76</td>\n",
              "      <td>38.76</td>\n",
              "      <td>7</td>\n",
              "      <td>450.0</td>\n",
              "      <td>WAKEFIELD HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>649.0</td>\n",
              "      <td>649.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>7.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>2,248</td>\n",
              "      <td></td>\n",
              "      <td>2,248</td>\n",
              "      <td>2248.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>ARLINGTON County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>Arlington County</td>\n",
              "      <td>80</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>93.61%</td>\n",
              "      <td>93.61</td>\n",
              "      <td>93.61</td>\n",
              "      <td>7</td>\n",
              "      <td>80</td>\n",
              "      <td>WASHINGTON LEE HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>2,249</td>\n",
              "      <td>597</td>\n",
              "      <td>26.55%</td>\n",
              "      <td>171</td>\n",
              "      <td>7.60%</td>\n",
              "      <td>768</td>\n",
              "      <td>34.15%</td>\n",
              "      <td>34.15</td>\n",
              "      <td>34.15</td>\n",
              "      <td>7</td>\n",
              "      <td>80.0</td>\n",
              "      <td>WASHINGTON-LEE HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1114.0</td>\n",
              "      <td>1114.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>7.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>2,437</td>\n",
              "      <td></td>\n",
              "      <td>2,437</td>\n",
              "      <td>2437.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>ARLINGTON County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>Arlington County</td>\n",
              "      <td>330</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>95.51%</td>\n",
              "      <td>95.51</td>\n",
              "      <td>95.51</td>\n",
              "      <td>7</td>\n",
              "      <td>330</td>\n",
              "      <td>YORKTOWN HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1,974</td>\n",
              "      <td>230</td>\n",
              "      <td>11.65%</td>\n",
              "      <td>58</td>\n",
              "      <td>2.94%</td>\n",
              "      <td>288</td>\n",
              "      <td>14.59%</td>\n",
              "      <td>14.59</td>\n",
              "      <td>14.59</td>\n",
              "      <td>7</td>\n",
              "      <td>330.0</td>\n",
              "      <td>YORKTOWN HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>944.0</td>\n",
              "      <td>944.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>7.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>2,190</td>\n",
              "      <td></td>\n",
              "      <td>2,190</td>\n",
              "      <td>2190.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>ARLINGTON County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2018</td>\n",
              "      <td>8</td>\n",
              "      <td>Augusta County</td>\n",
              "      <td>660</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>95.35%</td>\n",
              "      <td>95.35</td>\n",
              "      <td>95.35</td>\n",
              "      <td>8</td>\n",
              "      <td>660</td>\n",
              "      <td>BUFFALO GAP HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>488</td>\n",
              "      <td>137</td>\n",
              "      <td>28.07%</td>\n",
              "      <td>34</td>\n",
              "      <td>6.97%</td>\n",
              "      <td>171</td>\n",
              "      <td>35.04%</td>\n",
              "      <td>35.04</td>\n",
              "      <td>35.04</td>\n",
              "      <td>8</td>\n",
              "      <td>660.0</td>\n",
              "      <td>BUFFALO GAP HIGH</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>8.0</td>\n",
              "      <td>660.0</td>\n",
              "      <td>487</td>\n",
              "      <td></td>\n",
              "      <td>487</td>\n",
              "      <td>487.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>AUGUSTA County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2018</td>\n",
              "      <td>8</td>\n",
              "      <td>Augusta County</td>\n",
              "      <td>670</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>92.97%</td>\n",
              "      <td>92.97</td>\n",
              "      <td>92.97</td>\n",
              "      <td>8</td>\n",
              "      <td>670</td>\n",
              "      <td>FT DEFIANCE HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>779</td>\n",
              "      <td>200</td>\n",
              "      <td>25.67%</td>\n",
              "      <td>50</td>\n",
              "      <td>6.42%</td>\n",
              "      <td>250</td>\n",
              "      <td>32.09%</td>\n",
              "      <td>32.09</td>\n",
              "      <td>32.09</td>\n",
              "      <td>8</td>\n",
              "      <td>670.0</td>\n",
              "      <td>FORT DEFIANCE HIGH</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>8.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>787</td>\n",
              "      <td></td>\n",
              "      <td>787</td>\n",
              "      <td>787.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>AUGUSTA County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2018</td>\n",
              "      <td>8</td>\n",
              "      <td>Augusta County</td>\n",
              "      <td>680</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>97.25%</td>\n",
              "      <td>97.25</td>\n",
              "      <td>97.25</td>\n",
              "      <td>8</td>\n",
              "      <td>680</td>\n",
              "      <td>RIVERHEADS HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>455</td>\n",
              "      <td>101</td>\n",
              "      <td>22.20%</td>\n",
              "      <td>30</td>\n",
              "      <td>6.59%</td>\n",
              "      <td>131</td>\n",
              "      <td>28.79%</td>\n",
              "      <td>28.79</td>\n",
              "      <td>28.79</td>\n",
              "      <td>8</td>\n",
              "      <td>680.0</td>\n",
              "      <td>RIVERHEADS HIGH</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>8.0</td>\n",
              "      <td>680.0</td>\n",
              "      <td>460</td>\n",
              "      <td>1</td>\n",
              "      <td>461</td>\n",
              "      <td>461.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>AUGUSTA County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2018</td>\n",
              "      <td>8</td>\n",
              "      <td>Augusta County</td>\n",
              "      <td>730</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>96.11%</td>\n",
              "      <td>96.11</td>\n",
              "      <td>96.11</td>\n",
              "      <td>8</td>\n",
              "      <td>730</td>\n",
              "      <td>STUARTS DRAFT HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>713</td>\n",
              "      <td>184</td>\n",
              "      <td>25.81%</td>\n",
              "      <td>43</td>\n",
              "      <td>6.03%</td>\n",
              "      <td>227</td>\n",
              "      <td>31.84%</td>\n",
              "      <td>31.84</td>\n",
              "      <td>31.84</td>\n",
              "      <td>8</td>\n",
              "      <td>730.0</td>\n",
              "      <td>STUARTS DRAFT HIGH</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>8.0</td>\n",
              "      <td>730.0</td>\n",
              "      <td>722</td>\n",
              "      <td></td>\n",
              "      <td>722</td>\n",
              "      <td>722.0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>AUGUSTA County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2018</td>\n",
              "      <td>8</td>\n",
              "      <td>Augusta County</td>\n",
              "      <td>720</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>93.65%</td>\n",
              "      <td>93.65</td>\n",
              "      <td>93.65</td>\n",
              "      <td>8</td>\n",
              "      <td>720</td>\n",
              "      <td>WILSON MEMORIAL HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>766</td>\n",
              "      <td>195</td>\n",
              "      <td>25.46%</td>\n",
              "      <td>33</td>\n",
              "      <td>4.31%</td>\n",
              "      <td>228</td>\n",
              "      <td>29.77%</td>\n",
              "      <td>29.77</td>\n",
              "      <td>29.77</td>\n",
              "      <td>8</td>\n",
              "      <td>720.0</td>\n",
              "      <td>WILSON MEMORIAL HIGH</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>8.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>762</td>\n",
              "      <td></td>\n",
              "      <td>762</td>\n",
              "      <td>762.0</td>\n",
              "      <td>493.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>AUGUSTA County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2018</td>\n",
              "      <td>9</td>\n",
              "      <td>Bath County</td>\n",
              "      <td>140</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>93.62%</td>\n",
              "      <td>93.62</td>\n",
              "      <td>93.62</td>\n",
              "      <td>9</td>\n",
              "      <td>140</td>\n",
              "      <td>BATH COUNTY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>207</td>\n",
              "      <td>66</td>\n",
              "      <td>31.88%</td>\n",
              "      <td>17</td>\n",
              "      <td>8.21%</td>\n",
              "      <td>83</td>\n",
              "      <td>40.10%</td>\n",
              "      <td>40.10</td>\n",
              "      <td>40.10</td>\n",
              "      <td>9</td>\n",
              "      <td>140.0</td>\n",
              "      <td>BATH COUNTY HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>9.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>208</td>\n",
              "      <td></td>\n",
              "      <td>208</td>\n",
              "      <td>208.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>BATH County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2018</td>\n",
              "      <td>10</td>\n",
              "      <td>Bedford County</td>\n",
              "      <td>1212</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>93.53%</td>\n",
              "      <td>93.53</td>\n",
              "      <td>93.53</td>\n",
              "      <td>10</td>\n",
              "      <td>1212</td>\n",
              "      <td>JEFFERSON FOREST HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1,379</td>\n",
              "      <td>155</td>\n",
              "      <td>11.24%</td>\n",
              "      <td>35</td>\n",
              "      <td>2.54%</td>\n",
              "      <td>190</td>\n",
              "      <td>13.78%</td>\n",
              "      <td>13.78</td>\n",
              "      <td>13.78</td>\n",
              "      <td>10</td>\n",
              "      <td>1212.0</td>\n",
              "      <td>JEFFERSON FOREST HIGH</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1212.0</td>\n",
              "      <td>1,387</td>\n",
              "      <td>1</td>\n",
              "      <td>1,388</td>\n",
              "      <td>1388.0</td>\n",
              "      <td>1117.0</td>\n",
              "      <td>606.0</td>\n",
              "      <td>BEDFORD County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2018</td>\n",
              "      <td>10</td>\n",
              "      <td>Bedford County</td>\n",
              "      <td>1180</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>89.95%</td>\n",
              "      <td>89.95</td>\n",
              "      <td>89.95</td>\n",
              "      <td>10</td>\n",
              "      <td>1180</td>\n",
              "      <td>LIBERTY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>811</td>\n",
              "      <td>290</td>\n",
              "      <td>35.76%</td>\n",
              "      <td>63</td>\n",
              "      <td>7.77%</td>\n",
              "      <td>353</td>\n",
              "      <td>43.53%</td>\n",
              "      <td>43.53</td>\n",
              "      <td>43.53</td>\n",
              "      <td>10</td>\n",
              "      <td>1180.0</td>\n",
              "      <td>LIBERTY HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1180.0</td>\n",
              "      <td>812</td>\n",
              "      <td></td>\n",
              "      <td>812</td>\n",
              "      <td>812.0</td>\n",
              "      <td>1784.0</td>\n",
              "      <td>710.0</td>\n",
              "      <td>BEDFORD County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2018</td>\n",
              "      <td>10</td>\n",
              "      <td>Bedford County</td>\n",
              "      <td>1190</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>90.98%</td>\n",
              "      <td>90.98</td>\n",
              "      <td>90.98</td>\n",
              "      <td>10</td>\n",
              "      <td>1190</td>\n",
              "      <td>STAUNTON RIVER HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>966</td>\n",
              "      <td>335</td>\n",
              "      <td>34.68%</td>\n",
              "      <td>69</td>\n",
              "      <td>7.14%</td>\n",
              "      <td>404</td>\n",
              "      <td>41.82%</td>\n",
              "      <td>41.82</td>\n",
              "      <td>41.82</td>\n",
              "      <td>10</td>\n",
              "      <td>1190.0</td>\n",
              "      <td>STAUNTON RIVER HIGH</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1190.0</td>\n",
              "      <td>967</td>\n",
              "      <td></td>\n",
              "      <td>967</td>\n",
              "      <td>967.0</td>\n",
              "      <td>1870.0</td>\n",
              "      <td>1275.0</td>\n",
              "      <td>BEDFORD County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2018</td>\n",
              "      <td>11</td>\n",
              "      <td>Bland County</td>\n",
              "      <td>260</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>95.16%</td>\n",
              "      <td>95.16</td>\n",
              "      <td>95.16</td>\n",
              "      <td>11</td>\n",
              "      <td>260</td>\n",
              "      <td>BLAND COUNTY HIGH</td>\n",
              "      <td>Combined</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>386</td>\n",
              "      <td>140</td>\n",
              "      <td>36.27%</td>\n",
              "      <td>29</td>\n",
              "      <td>7.51%</td>\n",
              "      <td>169</td>\n",
              "      <td>43.78%</td>\n",
              "      <td>43.78</td>\n",
              "      <td>43.78</td>\n",
              "      <td>11</td>\n",
              "      <td>260.0</td>\n",
              "      <td>BLAND COUNTY HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>383</td>\n",
              "      <td></td>\n",
              "      <td>383</td>\n",
              "      <td>383.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>BLAND County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2018</td>\n",
              "      <td>12</td>\n",
              "      <td>Botetourt County</td>\n",
              "      <td>430</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>98.55%</td>\n",
              "      <td>98.55</td>\n",
              "      <td>98.55</td>\n",
              "      <td>12</td>\n",
              "      <td>430</td>\n",
              "      <td>JAMES RIVER HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>549</td>\n",
              "      <td>111</td>\n",
              "      <td>20.22%</td>\n",
              "      <td>35</td>\n",
              "      <td>6.38%</td>\n",
              "      <td>146</td>\n",
              "      <td>26.59%</td>\n",
              "      <td>26.59</td>\n",
              "      <td>26.59</td>\n",
              "      <td>12</td>\n",
              "      <td>430.0</td>\n",
              "      <td>JAMES RIVER HIGH</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>12.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>548</td>\n",
              "      <td></td>\n",
              "      <td>548</td>\n",
              "      <td>548.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>BOTETOURT County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2018</td>\n",
              "      <td>12</td>\n",
              "      <td>Botetourt County</td>\n",
              "      <td>440</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>93.39%</td>\n",
              "      <td>93.39</td>\n",
              "      <td>93.39</td>\n",
              "      <td>12</td>\n",
              "      <td>440</td>\n",
              "      <td>LORD BOTETOURT HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1,046</td>\n",
              "      <td>151</td>\n",
              "      <td>14.44%</td>\n",
              "      <td>32</td>\n",
              "      <td>3.06%</td>\n",
              "      <td>183</td>\n",
              "      <td>17.50%</td>\n",
              "      <td>17.50</td>\n",
              "      <td>17.50</td>\n",
              "      <td>12</td>\n",
              "      <td>440.0</td>\n",
              "      <td>LORD BOTETOURT HIGH</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>12.0</td>\n",
              "      <td>440.0</td>\n",
              "      <td>1,052</td>\n",
              "      <td></td>\n",
              "      <td>1,052</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>BOTETOURT County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2018</td>\n",
              "      <td>102</td>\n",
              "      <td>Bristol City</td>\n",
              "      <td>80</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>90.74%</td>\n",
              "      <td>90.74</td>\n",
              "      <td>90.74</td>\n",
              "      <td>102</td>\n",
              "      <td>80</td>\n",
              "      <td>VIRGINIA HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>648</td>\n",
              "      <td>306</td>\n",
              "      <td>47.22%</td>\n",
              "      <td>19</td>\n",
              "      <td>2.93%</td>\n",
              "      <td>325</td>\n",
              "      <td>50.15%</td>\n",
              "      <td>50.15</td>\n",
              "      <td>50.15</td>\n",
              "      <td>102</td>\n",
              "      <td>80.0</td>\n",
              "      <td>VIRGINIA HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>102.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>647</td>\n",
              "      <td></td>\n",
              "      <td>647</td>\n",
              "      <td>647.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>BRISTOL City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2018</td>\n",
              "      <td>13</td>\n",
              "      <td>Brunswick County</td>\n",
              "      <td>650</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>88.72%</td>\n",
              "      <td>88.72</td>\n",
              "      <td>88.72</td>\n",
              "      <td>13</td>\n",
              "      <td>650</td>\n",
              "      <td>BRUNSWICK HIGH (CEP-SEE NOTE 2)</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>489</td>\n",
              "      <td>472</td>\n",
              "      <td>96.52%</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>472</td>\n",
              "      <td>96.52%</td>\n",
              "      <td>96.52</td>\n",
              "      <td>96.52</td>\n",
              "      <td>13</td>\n",
              "      <td>650.0</td>\n",
              "      <td>BRUNSWICK HIGH</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>13.0</td>\n",
              "      <td>650.0</td>\n",
              "      <td>492</td>\n",
              "      <td></td>\n",
              "      <td>492</td>\n",
              "      <td>492.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>BRUNSWICK County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2018</td>\n",
              "      <td>14</td>\n",
              "      <td>Buchanan County</td>\n",
              "      <td>1000</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>95.24%</td>\n",
              "      <td>95.24</td>\n",
              "      <td>95.24</td>\n",
              "      <td>14</td>\n",
              "      <td>1000</td>\n",
              "      <td>COUNCIL HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>133</td>\n",
              "      <td>98</td>\n",
              "      <td>73.68%</td>\n",
              "      <td>13</td>\n",
              "      <td>9.77%</td>\n",
              "      <td>111</td>\n",
              "      <td>83.46%</td>\n",
              "      <td>83.46</td>\n",
              "      <td>83.46</td>\n",
              "      <td>14</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>COUNCIL HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>136</td>\n",
              "      <td></td>\n",
              "      <td>136</td>\n",
              "      <td>136.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>BUCHANAN County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2018</td>\n",
              "      <td>14</td>\n",
              "      <td>Buchanan County</td>\n",
              "      <td>990</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>94.39%</td>\n",
              "      <td>94.39</td>\n",
              "      <td>94.39</td>\n",
              "      <td>14</td>\n",
              "      <td>990</td>\n",
              "      <td>GRUNDY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>417</td>\n",
              "      <td>235</td>\n",
              "      <td>56.35%</td>\n",
              "      <td>43</td>\n",
              "      <td>10.31%</td>\n",
              "      <td>278</td>\n",
              "      <td>66.67%</td>\n",
              "      <td>66.67</td>\n",
              "      <td>66.67</td>\n",
              "      <td>14</td>\n",
              "      <td>990.0</td>\n",
              "      <td>GRUNDY HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>14.0</td>\n",
              "      <td>990.0</td>\n",
              "      <td>419</td>\n",
              "      <td></td>\n",
              "      <td>419</td>\n",
              "      <td>419.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>BUCHANAN County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2018</td>\n",
              "      <td>14</td>\n",
              "      <td>Buchanan County</td>\n",
              "      <td>1020</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>74.36%</td>\n",
              "      <td>74.36</td>\n",
              "      <td>74.36</td>\n",
              "      <td>14</td>\n",
              "      <td>1020</td>\n",
              "      <td>HURLEY HIGH (CEP-SEE NOTE 2)</td>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>236</td>\n",
              "      <td>203</td>\n",
              "      <td>86.02%</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>203</td>\n",
              "      <td>86.02%</td>\n",
              "      <td>86.02</td>\n",
              "      <td>86.02</td>\n",
              "      <td>14</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>HURLEY HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>236</td>\n",
              "      <td></td>\n",
              "      <td>236</td>\n",
              "      <td>236.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>BUCHANAN County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2018</td>\n",
              "      <td>14</td>\n",
              "      <td>Buchanan County</td>\n",
              "      <td>1042</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>90.74%</td>\n",
              "      <td>90.74</td>\n",
              "      <td>90.74</td>\n",
              "      <td>14</td>\n",
              "      <td>1042</td>\n",
              "      <td>TWIN VALLEY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>230</td>\n",
              "      <td>132</td>\n",
              "      <td>57.39%</td>\n",
              "      <td>30</td>\n",
              "      <td>13.04%</td>\n",
              "      <td>162</td>\n",
              "      <td>70.43%</td>\n",
              "      <td>70.43</td>\n",
              "      <td>70.43</td>\n",
              "      <td>14</td>\n",
              "      <td>1042.0</td>\n",
              "      <td>TWIN VALLEY HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1042.0</td>\n",
              "      <td>231</td>\n",
              "      <td></td>\n",
              "      <td>231</td>\n",
              "      <td>231.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>BUCHANAN County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2018</td>\n",
              "      <td>15</td>\n",
              "      <td>Buckingham County</td>\n",
              "      <td>700</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>95.28%</td>\n",
              "      <td>95.28</td>\n",
              "      <td>95.28</td>\n",
              "      <td>15</td>\n",
              "      <td>700</td>\n",
              "      <td>BUCKINGHAM COUNTY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>550</td>\n",
              "      <td>292</td>\n",
              "      <td>53.09%</td>\n",
              "      <td>64</td>\n",
              "      <td>11.64%</td>\n",
              "      <td>356</td>\n",
              "      <td>64.73%</td>\n",
              "      <td>64.73</td>\n",
              "      <td>64.73</td>\n",
              "      <td>15</td>\n",
              "      <td>700.0</td>\n",
              "      <td>BUCKINGHAM COUNTY HIGH</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>15.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>565</td>\n",
              "      <td></td>\n",
              "      <td>565</td>\n",
              "      <td>565.0</td>\n",
              "      <td>657.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>BUCKINGHAM County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2018</td>\n",
              "      <td>103</td>\n",
              "      <td>Buena Vista City</td>\n",
              "      <td>62</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>87.32%</td>\n",
              "      <td>87.32</td>\n",
              "      <td>87.32</td>\n",
              "      <td>103</td>\n",
              "      <td>62</td>\n",
              "      <td>PARRY MCCLUER HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>395</td>\n",
              "      <td>145</td>\n",
              "      <td>36.71%</td>\n",
              "      <td>22</td>\n",
              "      <td>5.57%</td>\n",
              "      <td>167</td>\n",
              "      <td>42.28%</td>\n",
              "      <td>42.28</td>\n",
              "      <td>42.28</td>\n",
              "      <td>103</td>\n",
              "      <td>62.0</td>\n",
              "      <td>PARRY MCCLUER HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>103.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>389</td>\n",
              "      <td></td>\n",
              "      <td>389</td>\n",
              "      <td>389.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>BUENA VISTA City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2018</td>\n",
              "      <td>16</td>\n",
              "      <td>Campbell County</td>\n",
              "      <td>200</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>84.69%</td>\n",
              "      <td>84.69</td>\n",
              "      <td>84.69</td>\n",
              "      <td>16</td>\n",
              "      <td>200</td>\n",
              "      <td>ALTAVISTA HIGH</td>\n",
              "      <td>Combined</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>608</td>\n",
              "      <td>258</td>\n",
              "      <td>42.43%</td>\n",
              "      <td>37</td>\n",
              "      <td>6.09%</td>\n",
              "      <td>295</td>\n",
              "      <td>48.52%</td>\n",
              "      <td>48.52</td>\n",
              "      <td>48.52</td>\n",
              "      <td>16</td>\n",
              "      <td>200.0</td>\n",
              "      <td>ALTAVISTA HIGH</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>16.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>663</td>\n",
              "      <td></td>\n",
              "      <td>663</td>\n",
              "      <td>663.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>CAMPBELL County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2018</td>\n",
              "      <td>16</td>\n",
              "      <td>Campbell County</td>\n",
              "      <td>720</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>93.59%</td>\n",
              "      <td>93.59</td>\n",
              "      <td>93.59</td>\n",
              "      <td>16</td>\n",
              "      <td>720</td>\n",
              "      <td>BROOKVILLE HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>849</td>\n",
              "      <td>203</td>\n",
              "      <td>23.91%</td>\n",
              "      <td>52</td>\n",
              "      <td>6.12%</td>\n",
              "      <td>255</td>\n",
              "      <td>30.04%</td>\n",
              "      <td>30.04</td>\n",
              "      <td>30.04</td>\n",
              "      <td>16</td>\n",
              "      <td>720.0</td>\n",
              "      <td>BROOKVILLE HIGH</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>16.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>925</td>\n",
              "      <td></td>\n",
              "      <td>925</td>\n",
              "      <td>925.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>CAMPBELL County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2018</td>\n",
              "      <td>16</td>\n",
              "      <td>Campbell County</td>\n",
              "      <td>222</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>91.42%</td>\n",
              "      <td>91.42</td>\n",
              "      <td>91.42</td>\n",
              "      <td>16</td>\n",
              "      <td>222</td>\n",
              "      <td>RUSTBURG HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>802</td>\n",
              "      <td>300</td>\n",
              "      <td>37.41%</td>\n",
              "      <td>53</td>\n",
              "      <td>6.61%</td>\n",
              "      <td>353</td>\n",
              "      <td>44.01%</td>\n",
              "      <td>44.01</td>\n",
              "      <td>44.01</td>\n",
              "      <td>16</td>\n",
              "      <td>222.0</td>\n",
              "      <td>RUSTBURG HIGH</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>16.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>865</td>\n",
              "      <td></td>\n",
              "      <td>865</td>\n",
              "      <td>865.0</td>\n",
              "      <td>437.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>CAMPBELL County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2018</td>\n",
              "      <td>16</td>\n",
              "      <td>Campbell County</td>\n",
              "      <td>542</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>94.74%</td>\n",
              "      <td>94.74</td>\n",
              "      <td>94.74</td>\n",
              "      <td>16</td>\n",
              "      <td>542</td>\n",
              "      <td>WILLIAM CAMPBELL HIGH</td>\n",
              "      <td>Combined</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>408</td>\n",
              "      <td>211</td>\n",
              "      <td>51.72%</td>\n",
              "      <td>25</td>\n",
              "      <td>6.13%</td>\n",
              "      <td>236</td>\n",
              "      <td>57.84%</td>\n",
              "      <td>57.84</td>\n",
              "      <td>57.84</td>\n",
              "      <td>16</td>\n",
              "      <td>542.0</td>\n",
              "      <td>WILLIAM CAMPBELL HIGH</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>16.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>435</td>\n",
              "      <td></td>\n",
              "      <td>435</td>\n",
              "      <td>435.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>CAMPBELL County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>2018</td>\n",
              "      <td>17</td>\n",
              "      <td>Caroline County</td>\n",
              "      <td>460</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>88.01%</td>\n",
              "      <td>88.01</td>\n",
              "      <td>88.01</td>\n",
              "      <td>17</td>\n",
              "      <td>460</td>\n",
              "      <td>CAROLINE HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1,169</td>\n",
              "      <td>452</td>\n",
              "      <td>38.67%</td>\n",
              "      <td>95</td>\n",
              "      <td>8.13%</td>\n",
              "      <td>547</td>\n",
              "      <td>46.79%</td>\n",
              "      <td>46.79</td>\n",
              "      <td>46.79</td>\n",
              "      <td>17</td>\n",
              "      <td>460.0</td>\n",
              "      <td>CAROLINE HIGH</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>17.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>1,170</td>\n",
              "      <td></td>\n",
              "      <td>1,170</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>417.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>CAROLINE County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>2018</td>\n",
              "      <td>18</td>\n",
              "      <td>Carroll County</td>\n",
              "      <td>1230</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>91.26%</td>\n",
              "      <td>91.26</td>\n",
              "      <td>91.26</td>\n",
              "      <td>18</td>\n",
              "      <td>1230</td>\n",
              "      <td>CARROLL COUNTY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1,076</td>\n",
              "      <td>455</td>\n",
              "      <td>42.29%</td>\n",
              "      <td>68</td>\n",
              "      <td>6.32%</td>\n",
              "      <td>523</td>\n",
              "      <td>48.61%</td>\n",
              "      <td>48.61</td>\n",
              "      <td>48.61</td>\n",
              "      <td>18</td>\n",
              "      <td>1230.0</td>\n",
              "      <td>CARROLL COUNTY HIGH</td>\n",
              "      <td>1.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1230.0</td>\n",
              "      <td>1,122</td>\n",
              "      <td></td>\n",
              "      <td>1,122</td>\n",
              "      <td>1122.0</td>\n",
              "      <td>431.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>CARROLL County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>2018</td>\n",
              "      <td>19</td>\n",
              "      <td>Charles City County</td>\n",
              "      <td>100</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>89.80%</td>\n",
              "      <td>89.80</td>\n",
              "      <td>89.80</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>CHARLES CITY CO HIGH</td>\n",
              "      <td>Combined</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>306</td>\n",
              "      <td>149</td>\n",
              "      <td>48.69%</td>\n",
              "      <td>25</td>\n",
              "      <td>8.17%</td>\n",
              "      <td>174</td>\n",
              "      <td>56.86%</td>\n",
              "      <td>56.86</td>\n",
              "      <td>56.86</td>\n",
              "      <td>19</td>\n",
              "      <td>100.0</td>\n",
              "      <td>CHARLES CITY COUNTY HIGH</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>19.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>305</td>\n",
              "      <td></td>\n",
              "      <td>305</td>\n",
              "      <td>305.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>CHARLES CITY County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>2018</td>\n",
              "      <td>20</td>\n",
              "      <td>Charlotte County</td>\n",
              "      <td>460</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>88.96%</td>\n",
              "      <td>88.96</td>\n",
              "      <td>88.96</td>\n",
              "      <td>20</td>\n",
              "      <td>460</td>\n",
              "      <td>RANDOLPH-HENRY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>525</td>\n",
              "      <td>204</td>\n",
              "      <td>38.86%</td>\n",
              "      <td>43</td>\n",
              "      <td>8.19%</td>\n",
              "      <td>247</td>\n",
              "      <td>47.05%</td>\n",
              "      <td>47.05</td>\n",
              "      <td>47.05</td>\n",
              "      <td>20</td>\n",
              "      <td>460.0</td>\n",
              "      <td>RANDOLPH-HENRY HIGH</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>20.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>531</td>\n",
              "      <td></td>\n",
              "      <td>531</td>\n",
              "      <td>531.0</td>\n",
              "      <td>266.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>CHARLOTTE County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2018</td>\n",
              "      <td>104</td>\n",
              "      <td>Charlottesville City</td>\n",
              "      <td>140</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>92.62%</td>\n",
              "      <td>92.62</td>\n",
              "      <td>92.62</td>\n",
              "      <td>104</td>\n",
              "      <td>140</td>\n",
              "      <td>CHARLOTTESVILLE HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1,204</td>\n",
              "      <td>519</td>\n",
              "      <td>43.11%</td>\n",
              "      <td>45</td>\n",
              "      <td>3.74%</td>\n",
              "      <td>564</td>\n",
              "      <td>46.84%</td>\n",
              "      <td>46.84</td>\n",
              "      <td>46.84</td>\n",
              "      <td>104</td>\n",
              "      <td>140.0</td>\n",
              "      <td>CHARLOTTESVILLE HIGH</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>452.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>104.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>1,172</td>\n",
              "      <td>1</td>\n",
              "      <td>1,173</td>\n",
              "      <td>1173.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>CHARLOTTESVILLE City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>2018</td>\n",
              "      <td>136</td>\n",
              "      <td>Chesapeake City</td>\n",
              "      <td>100</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>90.93%</td>\n",
              "      <td>90.93</td>\n",
              "      <td>90.93</td>\n",
              "      <td>136</td>\n",
              "      <td>100</td>\n",
              "      <td>DEEP CREEK HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1,607</td>\n",
              "      <td>595</td>\n",
              "      <td>37.03%</td>\n",
              "      <td>117</td>\n",
              "      <td>7.28%</td>\n",
              "      <td>712</td>\n",
              "      <td>44.31%</td>\n",
              "      <td>44.31</td>\n",
              "      <td>44.31</td>\n",
              "      <td>136</td>\n",
              "      <td>100.0</td>\n",
              "      <td>DEEP CREEK HIGH</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>136.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1,647</td>\n",
              "      <td></td>\n",
              "      <td>1,647</td>\n",
              "      <td>1647.0</td>\n",
              "      <td>433.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>CHESAPEAKE City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>2018</td>\n",
              "      <td>136</td>\n",
              "      <td>Chesapeake City</td>\n",
              "      <td>960</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>97.11%</td>\n",
              "      <td>97.11</td>\n",
              "      <td>97.11</td>\n",
              "      <td>136</td>\n",
              "      <td>960</td>\n",
              "      <td>GRASSFIELD HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>2,225</td>\n",
              "      <td>194</td>\n",
              "      <td>8.72%</td>\n",
              "      <td>76</td>\n",
              "      <td>3.42%</td>\n",
              "      <td>270</td>\n",
              "      <td>12.13%</td>\n",
              "      <td>12.13</td>\n",
              "      <td>12.13</td>\n",
              "      <td>136</td>\n",
              "      <td>960.0</td>\n",
              "      <td>GRASSFIELD HIGH</td>\n",
              "      <td>7.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>596.0</td>\n",
              "      <td>392.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>136.0</td>\n",
              "      <td>960.0</td>\n",
              "      <td>2,071</td>\n",
              "      <td></td>\n",
              "      <td>2,071</td>\n",
              "      <td>2071.0</td>\n",
              "      <td>456.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>CHESAPEAKE City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>2018</td>\n",
              "      <td>136</td>\n",
              "      <td>Chesapeake City</td>\n",
              "      <td>120</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>95.76%</td>\n",
              "      <td>95.76</td>\n",
              "      <td>95.76</td>\n",
              "      <td>136</td>\n",
              "      <td>120</td>\n",
              "      <td>GREAT BRIDGE HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1,383</td>\n",
              "      <td>214</td>\n",
              "      <td>15.47%</td>\n",
              "      <td>73</td>\n",
              "      <td>5.28%</td>\n",
              "      <td>287</td>\n",
              "      <td>20.75%</td>\n",
              "      <td>20.75</td>\n",
              "      <td>20.75</td>\n",
              "      <td>136</td>\n",
              "      <td>120.0</td>\n",
              "      <td>GREAT BRIDGE HIGH</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>136.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1,449</td>\n",
              "      <td></td>\n",
              "      <td>1,449</td>\n",
              "      <td>1449.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>CHESAPEAKE City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2018</td>\n",
              "      <td>136</td>\n",
              "      <td>Chesapeake City</td>\n",
              "      <td>890</td>\n",
              "      <td>On-Time Graduation Rate</td>\n",
              "      <td>4 yr rate</td>\n",
              "      <td>97.03%</td>\n",
              "      <td>97.03</td>\n",
              "      <td>97.03</td>\n",
              "      <td>136</td>\n",
              "      <td>890</td>\n",
              "      <td>HICKORY HIGH</td>\n",
              "      <td>High</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>1,751</td>\n",
              "      <td>136</td>\n",
              "      <td>7.77%</td>\n",
              "      <td>26</td>\n",
              "      <td>1.48%</td>\n",
              "      <td>162</td>\n",
              "      <td>9.25%</td>\n",
              "      <td>9.25</td>\n",
              "      <td>9.25</td>\n",
              "      <td>136</td>\n",
              "      <td>890.0</td>\n",
              "      <td>HICKORY HIGH</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>370.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>2017-2018</td>\n",
              "      <td>136.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>1,790</td>\n",
              "      <td></td>\n",
              "      <td>1,790</td>\n",
              "      <td>1790.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>CHESAPEAKE City</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Cohort Year  Division Number_x  ... TOT_DAYSMISSED_F                    nn\n",
              "0          2018                  1  ...             63.0       ACCOMACK County\n",
              "1          2018                  1  ...              3.0       ACCOMACK County\n",
              "2          2018                  1  ...             77.0       ACCOMACK County\n",
              "3          2018                  1  ...              0.0       ACCOMACK County\n",
              "4          2018                  2  ...            149.0      ALBEMARLE County\n",
              "5          2018                  2  ...            183.0      ALBEMARLE County\n",
              "6          2018                  2  ...             58.0      ALBEMARLE County\n",
              "7          2018                  2  ...             34.0      ALBEMARLE County\n",
              "8          2018                101  ...            372.0       ALEXANDRIA City\n",
              "9          2018                  3  ...            105.0      ALLEGHANY County\n",
              "10         2018                  4  ...            123.0         AMELIA County\n",
              "11         2018                  5  ...           3914.0        AMHERST County\n",
              "12         2018                  6  ...            280.0     APPOMATTOX County\n",
              "13         2018                  7  ...              0.0      ARLINGTON County\n",
              "14         2018                  7  ...             12.0      ARLINGTON County\n",
              "15         2018                  7  ...             30.0      ARLINGTON County\n",
              "16         2018                  7  ...             44.0      ARLINGTON County\n",
              "17         2018                  8  ...             58.0        AUGUSTA County\n",
              "18         2018                  8  ...             71.0        AUGUSTA County\n",
              "19         2018                  8  ...             41.0        AUGUSTA County\n",
              "20         2018                  8  ...             70.0        AUGUSTA County\n",
              "21         2018                  8  ...            180.0        AUGUSTA County\n",
              "22         2018                  9  ...              1.0           BATH County\n",
              "23         2018                 10  ...            606.0        BEDFORD County\n",
              "24         2018                 10  ...            710.0        BEDFORD County\n",
              "25         2018                 10  ...           1275.0        BEDFORD County\n",
              "26         2018                 11  ...             20.0          BLAND County\n",
              "27         2018                 12  ...             30.0      BOTETOURT County\n",
              "28         2018                 12  ...             57.0      BOTETOURT County\n",
              "29         2018                102  ...            107.0          BRISTOL City\n",
              "30         2018                 13  ...             86.0      BRUNSWICK County\n",
              "31         2018                 14  ...              8.0       BUCHANAN County\n",
              "32         2018                 14  ...              1.0       BUCHANAN County\n",
              "33         2018                 14  ...             28.0       BUCHANAN County\n",
              "34         2018                 14  ...              7.0       BUCHANAN County\n",
              "35         2018                 15  ...             96.0     BUCKINGHAM County\n",
              "36         2018                103  ...              1.0      BUENA VISTA City\n",
              "37         2018                 16  ...            119.0       CAMPBELL County\n",
              "38         2018                 16  ...            132.0       CAMPBELL County\n",
              "39         2018                 16  ...            120.0       CAMPBELL County\n",
              "40         2018                 16  ...             70.0       CAMPBELL County\n",
              "41         2018                 17  ...            113.0       CAROLINE County\n",
              "42         2018                 18  ...            139.0        CARROLL County\n",
              "43         2018                 19  ...            143.0   CHARLES CITY County\n",
              "44         2018                 20  ...             35.0      CHARLOTTE County\n",
              "45         2018                104  ...             46.0  CHARLOTTESVILLE City\n",
              "46         2018                136  ...            199.0       CHESAPEAKE City\n",
              "47         2018                136  ...            143.0       CHESAPEAKE City\n",
              "48         2018                136  ...             48.0       CHESAPEAKE City\n",
              "49         2018                136  ...             82.0       CHESAPEAKE City\n",
              "\n",
              "[50 rows x 45 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeyULLPBO89i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "82027811-c268-4469-ff19-3aa2a3c30f26"
      },
      "source": [
        "suspensiondays18.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>School Name</th>\n",
              "      <th>TOT_DAYSMISSED_M</th>\n",
              "      <th>TOT_DAYSMISSED_F</th>\n",
              "      <th>nn</th>\n",
              "      <th>Division Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CHINCOTEAGUE ELEMENTARY</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>ACCOMACK County</td>\n",
              "      <td>Accomack County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CHINCOTEAGUE HIGH</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>ACCOMACK County</td>\n",
              "      <td>Accomack County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KEGOTANK ELEMENTARY</td>\n",
              "      <td>114</td>\n",
              "      <td>16</td>\n",
              "      <td>ACCOMACK County</td>\n",
              "      <td>Accomack County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PUNGOTEAGUE ELEMENTARY</td>\n",
              "      <td>38</td>\n",
              "      <td>6</td>\n",
              "      <td>ACCOMACK County</td>\n",
              "      <td>Accomack County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANGIER COMBINED</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ACCOMACK County</td>\n",
              "      <td>Accomack County</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               School Name  TOT_DAYSMISSED_M  ...               nn    Division Name\n",
              "0  CHINCOTEAGUE ELEMENTARY                23  ...  ACCOMACK County  Accomack County\n",
              "1        CHINCOTEAGUE HIGH                 5  ...  ACCOMACK County  Accomack County\n",
              "2      KEGOTANK ELEMENTARY               114  ...  ACCOMACK County  Accomack County\n",
              "3   PUNGOTEAGUE ELEMENTARY                38  ...  ACCOMACK County  Accomack County\n",
              "4         TANGIER COMBINED                 0  ...  ACCOMACK County  Accomack County\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiI9VmyzPYgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b156f36-0736-4618-d7ab-6b934f07283c"
      },
      "source": [
        "food19.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2328 entries, 0 to 2327\n",
            "Data columns (total 17 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   DN               2328 non-null   object \n",
            " 1   notnumber        2145 non-null   object \n",
            " 2   School Name      2145 non-null   object \n",
            " 3   School Type      2145 non-null   object \n",
            " 4   Low Grade        2145 non-null   object \n",
            " 5   High Grade       2145 non-null   object \n",
            " 6   SNP Memb         2143 non-null   object \n",
            " 7   FREE Elig.       2143 non-null   object \n",
            " 8   FREE %           2143 non-null   object \n",
            " 9   RED Elig.        2143 non-null   object \n",
            " 10  RED %            2143 non-null   object \n",
            " 11  TOTAL F/R Elig.  2143 non-null   object \n",
            " 12  TOTAL F/R %      2143 non-null   object \n",
            " 13  School Number    2328 non-null   int64  \n",
            " 14  Division Number  1988 non-null   float64\n",
            " 15  FR               2143 non-null   object \n",
            " 16  FR%              2324 non-null   float64\n",
            "dtypes: float64(2), int64(1), object(14)\n",
            "memory usage: 309.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiNslfemh6fQ"
      },
      "source": [
        "# Data Cleansing and Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9II1B-BtndH"
      },
      "source": [
        "Dropping Columns:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43_Vsf3HO-Qz"
      },
      "source": [
        "#dropping unneccessary columns\n",
        "schooldata = comb3.drop(columns=['Cohort Year', 'Division Name','Type of Graduation Rate', 'School Name', 'School Number_x','Cohort Year','Rate Type','Graduation Rate','GradRate','DN','notnumber','School Type','Low Grade','High Grade','SNP Memb'])\n",
        "schooldata = schooldata.drop(columns=['School Name_y','FREE Elig.','FREE %','RED Elig.','RED %','TOTAL F/R Elig.','TOTAL F/R %'])\n",
        "schooldata = schooldata.drop(columns=['FR','Division Number_y','School Number_y','School Year','Division Number','Full Time Count (All Grades)','Part Time Count (All Grades)','Total Count','nn'])\n",
        "schooldata = schooldata.drop(columns=['School Number'])\n",
        "schooldata = schooldata.drop(columns=['Division Number_x'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GYSUsaeF8h7o",
        "outputId": "00b99201-1777-4b76-dc9d-556a80354ab1"
      },
      "source": [
        "schooldata.info()\n",
        "schooldata.head(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 332 entries, 0 to 331\n",
            "Data columns (total 13 columns):\n",
            " #   Column                                               Non-Null Count  Dtype  \n",
            "---  ------                                               --------------  -----  \n",
            " 0   GrRa                                                 324 non-null    float64\n",
            " 1   FR%                                                  329 non-null    float64\n",
            " 2   Governor's School Enrollment                         330 non-null    float64\n",
            " 3   Governor's STEM Academy                              330 non-null    float64\n",
            " 4   Governor's Health Academy                            330 non-null    float64\n",
            " 5   Seniors Awarded IB Diplomas                          330 non-null    float64\n",
            " 6   Senior IB Enrollment                                 330 non-null    float64\n",
            " 7   Students taking 1 or more AP Courses                 330 non-null    float64\n",
            " 8   Students taking 1 or more AP Exams                   330 non-null    float64\n",
            " 9   Students taking 1 or more Dual Enrollment Courses 1  330 non-null    float64\n",
            " 10  Student Count                                        327 non-null    float64\n",
            " 11  TOT_DAYSMISSED_M                                     319 non-null    float64\n",
            " 12  TOT_DAYSMISSED_F                                     319 non-null    float64\n",
            "dtypes: float64(13)\n",
            "memory usage: 36.3 KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GrRa</th>\n",
              "      <th>FR%</th>\n",
              "      <th>Governor's School Enrollment</th>\n",
              "      <th>Governor's STEM Academy</th>\n",
              "      <th>Governor's Health Academy</th>\n",
              "      <th>Seniors Awarded IB Diplomas</th>\n",
              "      <th>Senior IB Enrollment</th>\n",
              "      <th>Students taking 1 or more AP Courses</th>\n",
              "      <th>Students taking 1 or more AP Exams</th>\n",
              "      <th>Students taking 1 or more Dual Enrollment Courses 1</th>\n",
              "      <th>Student Count</th>\n",
              "      <th>TOT_DAYSMISSED_M</th>\n",
              "      <th>TOT_DAYSMISSED_F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82.47</td>\n",
              "      <td>63.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>622.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100.00</td>\n",
              "      <td>35.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>85.56</td>\n",
              "      <td>51.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>740.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>77.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>38.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>94.06</td>\n",
              "      <td>29.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>448.0</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>419.0</td>\n",
              "      <td>149.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>87.46</td>\n",
              "      <td>33.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>283.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>1133.0</td>\n",
              "      <td>293.0</td>\n",
              "      <td>183.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>72.22</td>\n",
              "      <td>24.24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>98.25</td>\n",
              "      <td>11.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>502.0</td>\n",
              "      <td>417.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>1139.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>80.64</td>\n",
              "      <td>55.67</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>976.0</td>\n",
              "      <td>976.0</td>\n",
              "      <td>414.0</td>\n",
              "      <td>3974.0</td>\n",
              "      <td>967.0</td>\n",
              "      <td>372.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>93.63</td>\n",
              "      <td>41.22</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>729.0</td>\n",
              "      <td>1043.0</td>\n",
              "      <td>105.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>90.30</td>\n",
              "      <td>41.20</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>547.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>123.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>93.25</td>\n",
              "      <td>43.45</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>1183.0</td>\n",
              "      <td>2809.0</td>\n",
              "      <td>3914.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>93.81</td>\n",
              "      <td>43.95</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>574.0</td>\n",
              "      <td>280.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>40.54</td>\n",
              "      <td>41.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>91.00</td>\n",
              "      <td>38.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>649.0</td>\n",
              "      <td>649.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2248.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>93.61</td>\n",
              "      <td>34.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1114.0</td>\n",
              "      <td>1114.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>2437.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>95.51</td>\n",
              "      <td>14.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>944.0</td>\n",
              "      <td>944.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2190.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>95.35</td>\n",
              "      <td>35.04</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>487.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>92.97</td>\n",
              "      <td>32.09</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>787.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>97.25</td>\n",
              "      <td>28.79</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>461.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>96.11</td>\n",
              "      <td>31.84</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>722.0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>93.65</td>\n",
              "      <td>29.77</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>762.0</td>\n",
              "      <td>493.0</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>93.62</td>\n",
              "      <td>40.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>93.53</td>\n",
              "      <td>13.78</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>1388.0</td>\n",
              "      <td>1117.0</td>\n",
              "      <td>606.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>89.95</td>\n",
              "      <td>43.53</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>812.0</td>\n",
              "      <td>1784.0</td>\n",
              "      <td>710.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>90.98</td>\n",
              "      <td>41.82</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>967.0</td>\n",
              "      <td>1870.0</td>\n",
              "      <td>1275.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>95.16</td>\n",
              "      <td>43.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>98.55</td>\n",
              "      <td>26.59</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>548.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>93.39</td>\n",
              "      <td>17.50</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>57.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>90.74</td>\n",
              "      <td>50.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>647.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>107.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>88.72</td>\n",
              "      <td>96.52</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>492.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>86.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>95.24</td>\n",
              "      <td>83.46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>94.39</td>\n",
              "      <td>66.67</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>419.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>74.36</td>\n",
              "      <td>86.02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>90.74</td>\n",
              "      <td>70.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>95.28</td>\n",
              "      <td>64.73</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>657.0</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>87.32</td>\n",
              "      <td>42.28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>389.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>84.69</td>\n",
              "      <td>48.52</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>663.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>119.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>93.59</td>\n",
              "      <td>30.04</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>132.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>91.42</td>\n",
              "      <td>44.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>865.0</td>\n",
              "      <td>437.0</td>\n",
              "      <td>120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>94.74</td>\n",
              "      <td>57.84</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>435.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>88.01</td>\n",
              "      <td>46.79</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>417.0</td>\n",
              "      <td>113.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>91.26</td>\n",
              "      <td>48.61</td>\n",
              "      <td>1.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>1122.0</td>\n",
              "      <td>431.0</td>\n",
              "      <td>139.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>89.80</td>\n",
              "      <td>56.86</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>305.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>143.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>88.96</td>\n",
              "      <td>47.05</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>266.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>92.62</td>\n",
              "      <td>46.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>452.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>1173.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>90.93</td>\n",
              "      <td>44.31</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>1647.0</td>\n",
              "      <td>433.0</td>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>97.11</td>\n",
              "      <td>12.13</td>\n",
              "      <td>7.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>596.0</td>\n",
              "      <td>392.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2071.0</td>\n",
              "      <td>456.0</td>\n",
              "      <td>143.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>95.76</td>\n",
              "      <td>20.75</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>1449.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>48.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>97.03</td>\n",
              "      <td>9.25</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>370.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1790.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>82.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      GrRa    FR%  ...  TOT_DAYSMISSED_M  TOT_DAYSMISSED_F\n",
              "0    82.47  63.93  ...              85.0              63.0\n",
              "1   100.00  35.96  ...               5.0               3.0\n",
              "2    85.56  51.47  ...             219.0              77.0\n",
              "3      NaN  38.71  ...               0.0               0.0\n",
              "4    94.06  29.22  ...             419.0             149.0\n",
              "5    87.46  33.33  ...             293.0             183.0\n",
              "6    72.22  24.24  ...              44.0              58.0\n",
              "7    98.25  11.19  ...             123.0              34.0\n",
              "8    80.64  55.67  ...             967.0             372.0\n",
              "9    93.63  41.22  ...            1043.0             105.0\n",
              "10   90.30  41.20  ...             514.0             123.0\n",
              "11   93.25  43.45  ...            2809.0            3914.0\n",
              "12   93.81  43.95  ...             574.0             280.0\n",
              "13   40.54  41.18  ...               0.0               0.0\n",
              "14   91.00  38.76  ...             106.0              12.0\n",
              "15   93.61  34.15  ...             123.0              30.0\n",
              "16   95.51  14.59  ...              55.0              44.0\n",
              "17   95.35  35.04  ...             256.0              58.0\n",
              "18   92.97  32.09  ...             194.0              71.0\n",
              "19   97.25  28.79  ...             252.0              41.0\n",
              "20   96.11  31.84  ...             245.0              70.0\n",
              "21   93.65  29.77  ...             493.0             180.0\n",
              "22   93.62  40.10  ...             179.0               1.0\n",
              "23   93.53  13.78  ...            1117.0             606.0\n",
              "24   89.95  43.53  ...            1784.0             710.0\n",
              "25   90.98  41.82  ...            1870.0            1275.0\n",
              "26   95.16  43.78  ...              87.0              20.0\n",
              "27   98.55  26.59  ...              92.0              30.0\n",
              "28   93.39  17.50  ...             237.0              57.0\n",
              "29   90.74  50.15  ...             186.0             107.0\n",
              "30   88.72  96.52  ...              91.0              86.0\n",
              "31   95.24  83.46  ...               2.0               8.0\n",
              "32   94.39  66.67  ...              85.0               1.0\n",
              "33   74.36  86.02  ...              68.0              28.0\n",
              "34   90.74  70.43  ...              20.0               7.0\n",
              "35   95.28  64.73  ...             657.0              96.0\n",
              "36   87.32  42.28  ...              67.0               1.0\n",
              "37   84.69  48.52  ...             255.0             119.0\n",
              "38   93.59  30.04  ...             279.0             132.0\n",
              "39   91.42  44.01  ...             437.0             120.0\n",
              "40   94.74  57.84  ...             218.0              70.0\n",
              "41   88.01  46.79  ...             417.0             113.0\n",
              "42   91.26  48.61  ...             431.0             139.0\n",
              "43   89.80  56.86  ...             198.0             143.0\n",
              "44   88.96  47.05  ...             266.0              35.0\n",
              "45   92.62  46.84  ...             207.0              46.0\n",
              "46   90.93  44.31  ...             433.0             199.0\n",
              "47   97.11  12.13  ...             456.0             143.0\n",
              "48   95.76  20.75  ...             312.0              48.0\n",
              "49   97.03   9.25  ...             472.0              82.0\n",
              "\n",
              "[50 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76sANc0wIQRA"
      },
      "source": [
        "Renaming Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQVmvvc7IFRA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "725c3d3f-b11b-4a5e-aca2-c9519932227c"
      },
      "source": [
        "#Rename columns to be more readable\n",
        "\n",
        "schooldata = schooldata.rename(columns={'FR%':'Free/Reduced Lunch %', 'GrRa':'4 Year Graduation Rate'})\n",
        "#schooldata.info()\n",
        "schooldata.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>4 Year Graduation Rate</th>\n",
              "      <th>Free/Reduced Lunch %</th>\n",
              "      <th>Governor's School Enrollment</th>\n",
              "      <th>Governor's STEM Academy</th>\n",
              "      <th>Governor's Health Academy</th>\n",
              "      <th>Seniors Awarded IB Diplomas</th>\n",
              "      <th>Senior IB Enrollment</th>\n",
              "      <th>Students taking 1 or more AP Courses</th>\n",
              "      <th>Students taking 1 or more AP Exams</th>\n",
              "      <th>Students taking 1 or more Dual Enrollment Courses 1</th>\n",
              "      <th>Student Count</th>\n",
              "      <th>TOT_DAYSMISSED_M</th>\n",
              "      <th>TOT_DAYSMISSED_F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>324.00000</td>\n",
              "      <td>329.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>327.000000</td>\n",
              "      <td>319.000000</td>\n",
              "      <td>319.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>91.14071</td>\n",
              "      <td>43.744377</td>\n",
              "      <td>18.730303</td>\n",
              "      <td>9.496970</td>\n",
              "      <td>3.796970</td>\n",
              "      <td>3.303030</td>\n",
              "      <td>5.190909</td>\n",
              "      <td>264.066667</td>\n",
              "      <td>194.615152</td>\n",
              "      <td>102.621212</td>\n",
              "      <td>1210.926606</td>\n",
              "      <td>474.351097</td>\n",
              "      <td>224.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.80770</td>\n",
              "      <td>23.465268</td>\n",
              "      <td>100.737840</td>\n",
              "      <td>34.920948</td>\n",
              "      <td>28.294339</td>\n",
              "      <td>14.006913</td>\n",
              "      <td>19.297776</td>\n",
              "      <td>294.691021</td>\n",
              "      <td>271.809070</td>\n",
              "      <td>102.755673</td>\n",
              "      <td>749.957754</td>\n",
              "      <td>620.995966</td>\n",
              "      <td>393.696660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.19000</td>\n",
              "      <td>1.850000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>89.56750</td>\n",
              "      <td>28.030000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.250000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>559.000000</td>\n",
              "      <td>109.500000</td>\n",
              "      <td>33.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>93.21500</td>\n",
              "      <td>42.080000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>71.500000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>1135.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>94.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>95.46500</td>\n",
              "      <td>56.660000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>421.500000</td>\n",
              "      <td>273.500000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>1763.500000</td>\n",
              "      <td>528.000000</td>\n",
              "      <td>215.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.00000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1805.000000</td>\n",
              "      <td>316.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>1469.000000</td>\n",
              "      <td>1452.000000</td>\n",
              "      <td>489.000000</td>\n",
              "      <td>4300.000000</td>\n",
              "      <td>3483.000000</td>\n",
              "      <td>3914.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       4 Year Graduation Rate  ...  TOT_DAYSMISSED_F\n",
              "count               324.00000  ...        319.000000\n",
              "mean                 91.14071  ...        224.545455\n",
              "std                   9.80770  ...        393.696660\n",
              "min                   3.19000  ...          0.000000\n",
              "25%                  89.56750  ...         33.000000\n",
              "50%                  93.21500  ...         94.000000\n",
              "75%                  95.46500  ...        215.500000\n",
              "max                 100.00000  ...       3914.000000\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "069SmsePLr5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "0cfa08d9-1a05-457f-91a9-3375694ad0d1"
      },
      "source": [
        "schooldata.corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>4 Year Graduation Rate</th>\n",
              "      <th>Free/Reduced Lunch %</th>\n",
              "      <th>Governor's School Enrollment</th>\n",
              "      <th>Governor's STEM Academy</th>\n",
              "      <th>Governor's Health Academy</th>\n",
              "      <th>Seniors Awarded IB Diplomas</th>\n",
              "      <th>Senior IB Enrollment</th>\n",
              "      <th>Students taking 1 or more AP Courses</th>\n",
              "      <th>Students taking 1 or more AP Exams</th>\n",
              "      <th>Students taking 1 or more Dual Enrollment Courses 1</th>\n",
              "      <th>Student Count</th>\n",
              "      <th>TOT_DAYSMISSED_M</th>\n",
              "      <th>TOT_DAYSMISSED_F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4 Year Graduation Rate</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.384786</td>\n",
              "      <td>0.063664</td>\n",
              "      <td>0.013693</td>\n",
              "      <td>0.020743</td>\n",
              "      <td>0.033059</td>\n",
              "      <td>0.049583</td>\n",
              "      <td>0.243914</td>\n",
              "      <td>0.208914</td>\n",
              "      <td>0.165877</td>\n",
              "      <td>0.108891</td>\n",
              "      <td>-0.104200</td>\n",
              "      <td>-0.103385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Free/Reduced Lunch %</th>\n",
              "      <td>-0.384786</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.101744</td>\n",
              "      <td>-0.001687</td>\n",
              "      <td>-0.061639</td>\n",
              "      <td>-0.083197</td>\n",
              "      <td>-0.086194</td>\n",
              "      <td>-0.544932</td>\n",
              "      <td>-0.494456</td>\n",
              "      <td>-0.270654</td>\n",
              "      <td>-0.400747</td>\n",
              "      <td>0.176600</td>\n",
              "      <td>0.223801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Governor's School Enrollment</th>\n",
              "      <td>0.063664</td>\n",
              "      <td>-0.101744</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.015826</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>-0.030459</td>\n",
              "      <td>-0.028978</td>\n",
              "      <td>0.193902</td>\n",
              "      <td>0.221819</td>\n",
              "      <td>-0.037515</td>\n",
              "      <td>0.060574</td>\n",
              "      <td>0.255373</td>\n",
              "      <td>0.225747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Governor's STEM Academy</th>\n",
              "      <td>0.013693</td>\n",
              "      <td>-0.001687</td>\n",
              "      <td>-0.015826</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.035696</td>\n",
              "      <td>0.004476</td>\n",
              "      <td>-0.016388</td>\n",
              "      <td>0.090028</td>\n",
              "      <td>0.051701</td>\n",
              "      <td>0.008040</td>\n",
              "      <td>0.113395</td>\n",
              "      <td>0.179922</td>\n",
              "      <td>0.197221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Governor's Health Academy</th>\n",
              "      <td>0.020743</td>\n",
              "      <td>-0.061639</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>-0.035696</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.008871</td>\n",
              "      <td>-0.019607</td>\n",
              "      <td>0.085208</td>\n",
              "      <td>0.074239</td>\n",
              "      <td>0.091741</td>\n",
              "      <td>0.081037</td>\n",
              "      <td>0.183989</td>\n",
              "      <td>0.162986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Seniors Awarded IB Diplomas</th>\n",
              "      <td>0.033059</td>\n",
              "      <td>-0.083197</td>\n",
              "      <td>-0.030459</td>\n",
              "      <td>0.004476</td>\n",
              "      <td>-0.008871</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.910631</td>\n",
              "      <td>0.060446</td>\n",
              "      <td>0.081707</td>\n",
              "      <td>-0.112410</td>\n",
              "      <td>0.294250</td>\n",
              "      <td>-0.021381</td>\n",
              "      <td>-0.033345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Senior IB Enrollment</th>\n",
              "      <td>0.049583</td>\n",
              "      <td>-0.086194</td>\n",
              "      <td>-0.028978</td>\n",
              "      <td>-0.016388</td>\n",
              "      <td>-0.019607</td>\n",
              "      <td>0.910631</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.050315</td>\n",
              "      <td>0.053966</td>\n",
              "      <td>-0.139510</td>\n",
              "      <td>0.271619</td>\n",
              "      <td>0.011515</td>\n",
              "      <td>0.006485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Students taking 1 or more AP Courses</th>\n",
              "      <td>0.243914</td>\n",
              "      <td>-0.544932</td>\n",
              "      <td>0.193902</td>\n",
              "      <td>0.090028</td>\n",
              "      <td>0.085208</td>\n",
              "      <td>0.060446</td>\n",
              "      <td>0.050315</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.915141</td>\n",
              "      <td>0.216485</td>\n",
              "      <td>0.776637</td>\n",
              "      <td>0.016428</td>\n",
              "      <td>-0.013131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Students taking 1 or more AP Exams</th>\n",
              "      <td>0.208914</td>\n",
              "      <td>-0.494456</td>\n",
              "      <td>0.221819</td>\n",
              "      <td>0.051701</td>\n",
              "      <td>0.074239</td>\n",
              "      <td>0.081707</td>\n",
              "      <td>0.053966</td>\n",
              "      <td>0.915141</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.207412</td>\n",
              "      <td>0.691103</td>\n",
              "      <td>-0.072431</td>\n",
              "      <td>-0.082646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Students taking 1 or more Dual Enrollment Courses 1</th>\n",
              "      <td>0.165877</td>\n",
              "      <td>-0.270654</td>\n",
              "      <td>-0.037515</td>\n",
              "      <td>0.008040</td>\n",
              "      <td>0.091741</td>\n",
              "      <td>-0.112410</td>\n",
              "      <td>-0.139510</td>\n",
              "      <td>0.216485</td>\n",
              "      <td>0.207412</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.227624</td>\n",
              "      <td>-0.015736</td>\n",
              "      <td>-0.052400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Student Count</th>\n",
              "      <td>0.108891</td>\n",
              "      <td>-0.400747</td>\n",
              "      <td>0.060574</td>\n",
              "      <td>0.113395</td>\n",
              "      <td>0.081037</td>\n",
              "      <td>0.294250</td>\n",
              "      <td>0.271619</td>\n",
              "      <td>0.776637</td>\n",
              "      <td>0.691103</td>\n",
              "      <td>0.227624</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.221607</td>\n",
              "      <td>0.136172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOT_DAYSMISSED_M</th>\n",
              "      <td>-0.104200</td>\n",
              "      <td>0.176600</td>\n",
              "      <td>0.255373</td>\n",
              "      <td>0.179922</td>\n",
              "      <td>0.183989</td>\n",
              "      <td>-0.021381</td>\n",
              "      <td>0.011515</td>\n",
              "      <td>0.016428</td>\n",
              "      <td>-0.072431</td>\n",
              "      <td>-0.015736</td>\n",
              "      <td>0.221607</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.830708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOT_DAYSMISSED_F</th>\n",
              "      <td>-0.103385</td>\n",
              "      <td>0.223801</td>\n",
              "      <td>0.225747</td>\n",
              "      <td>0.197221</td>\n",
              "      <td>0.162986</td>\n",
              "      <td>-0.033345</td>\n",
              "      <td>0.006485</td>\n",
              "      <td>-0.013131</td>\n",
              "      <td>-0.082646</td>\n",
              "      <td>-0.052400</td>\n",
              "      <td>0.136172</td>\n",
              "      <td>0.830708</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    4 Year Graduation Rate  ...  TOT_DAYSMISSED_F\n",
              "4 Year Graduation Rate                                            1.000000  ...         -0.103385\n",
              "Free/Reduced Lunch %                                             -0.384786  ...          0.223801\n",
              "Governor's School Enrollment                                      0.063664  ...          0.225747\n",
              "Governor's STEM Academy                                           0.013693  ...          0.197221\n",
              "Governor's Health Academy                                         0.020743  ...          0.162986\n",
              "Seniors Awarded IB Diplomas                                       0.033059  ...         -0.033345\n",
              "Senior IB Enrollment                                              0.049583  ...          0.006485\n",
              "Students taking 1 or more AP Courses                              0.243914  ...         -0.013131\n",
              "Students taking 1 or more AP Exams                                0.208914  ...         -0.082646\n",
              "Students taking 1 or more Dual Enrollment Cours...                0.165877  ...         -0.052400\n",
              "Student Count                                                     0.108891  ...          0.136172\n",
              "TOT_DAYSMISSED_M                                                 -0.104200  ...          0.830708\n",
              "TOT_DAYSMISSED_F                                                 -0.103385  ...          1.000000\n",
              "\n",
              "[13 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schooldata.plot(kind=\"scatter\", x=\"4 Year Graduation Rate\", y=\"Free/Reduced Lunch %\",\n",
        "             alpha=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "HmfG3ntFC-9m",
        "outputId": "6ec48d8a-bd16-4e24-b564-4b113be5d087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f46e93704d0>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schooldata.plot(kind=\"scatter\", x=\"4 Year Graduation Rate\", y=\"Students taking 1 or more AP Courses\",\n",
        "             alpha=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "LK2EGeVqEAVp",
        "outputId": "608d77bf-0280-4043-b80e-c52c812dcb43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f46e9338d50>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6MhEJsqJnxv"
      },
      "source": [
        "Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKk4uxGIKt6C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "939942b6-a5eb-4f02-f24d-5c0940785b3c"
      },
      "source": [
        "schooldata['Total Days Missed'] = schooldata['TOT_DAYSMISSED_M'] + schooldata['TOT_DAYSMISSED_F']\n",
        "\n",
        "# normalize data --> percentages rather than total counts of students\n",
        "schooldata['GovEnrPerStu'] = schooldata['Governor\\'s School Enrollment'] / schooldata['Student Count']\n",
        "schooldata['GovStemPerStu'] = schooldata['Governor\\'s STEM Academy'] / schooldata['Student Count']\n",
        "schooldata['GovHeaPerStu'] = schooldata['Governor\\'s Health Academy'] / schooldata['Student Count']\n",
        "schooldata['IBDipPerStu'] = schooldata['Seniors Awarded IB Diplomas'] / schooldata['Student Count']\n",
        "schooldata['IBEnrPerStu'] = schooldata['Senior IB Enrollment'] / schooldata['Student Count']\n",
        "schooldata['APEnrPerStu'] = schooldata['Students taking 1 or more AP Courses'] / schooldata['Student Count']\n",
        "schooldata['APExPerStu'] = schooldata['Students taking 1 or more AP Exams'] / schooldata['Student Count']\n",
        "schooldata['APEnrPerStu'] = schooldata['Students taking 1 or more Dual Enrollment Courses 1'] / schooldata['Student Count']\n",
        "schooldata['TotalDaysMissedPerStu'] = schooldata['Total Days Missed'] / schooldata['Student Count']\n",
        "schooldata['MDaysMissedPerStu'] = schooldata['TOT_DAYSMISSED_M'] / schooldata['Student Count']\n",
        "schooldata['FDaysMissedPerStu'] = schooldata['TOT_DAYSMISSED_F'] / schooldata['Student Count']\n",
        "schooldata.corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>4 Year Graduation Rate</th>\n",
              "      <th>Free/Reduced Lunch %</th>\n",
              "      <th>Governor's School Enrollment</th>\n",
              "      <th>Governor's STEM Academy</th>\n",
              "      <th>Governor's Health Academy</th>\n",
              "      <th>Seniors Awarded IB Diplomas</th>\n",
              "      <th>Senior IB Enrollment</th>\n",
              "      <th>Students taking 1 or more AP Courses</th>\n",
              "      <th>Students taking 1 or more AP Exams</th>\n",
              "      <th>Students taking 1 or more Dual Enrollment Courses 1</th>\n",
              "      <th>Student Count</th>\n",
              "      <th>TOT_DAYSMISSED_M</th>\n",
              "      <th>TOT_DAYSMISSED_F</th>\n",
              "      <th>Total Days Missed</th>\n",
              "      <th>GovEnrPerStu</th>\n",
              "      <th>GovStemPerStu</th>\n",
              "      <th>GovHeaPerStu</th>\n",
              "      <th>IBDipPerStu</th>\n",
              "      <th>IBEnrPerStu</th>\n",
              "      <th>APEnrPerStu</th>\n",
              "      <th>APExPerStu</th>\n",
              "      <th>TotalDaysMissedPerStu</th>\n",
              "      <th>MDaysMissedPerStu</th>\n",
              "      <th>FDaysMissedPerStu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4 Year Graduation Rate</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.384786</td>\n",
              "      <td>0.063664</td>\n",
              "      <td>0.013693</td>\n",
              "      <td>0.020743</td>\n",
              "      <td>0.033059</td>\n",
              "      <td>0.049583</td>\n",
              "      <td>0.243914</td>\n",
              "      <td>0.208914</td>\n",
              "      <td>0.165877</td>\n",
              "      <td>0.108891</td>\n",
              "      <td>-0.104200</td>\n",
              "      <td>-0.103385</td>\n",
              "      <td>-0.108357</td>\n",
              "      <td>0.068458</td>\n",
              "      <td>0.008757</td>\n",
              "      <td>0.010755</td>\n",
              "      <td>0.035814</td>\n",
              "      <td>0.067344</td>\n",
              "      <td>0.026790</td>\n",
              "      <td>0.257149</td>\n",
              "      <td>-0.167456</td>\n",
              "      <td>-0.152500</td>\n",
              "      <td>-0.170833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Free/Reduced Lunch %</th>\n",
              "      <td>-0.384786</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.101744</td>\n",
              "      <td>-0.001687</td>\n",
              "      <td>-0.061639</td>\n",
              "      <td>-0.083197</td>\n",
              "      <td>-0.086194</td>\n",
              "      <td>-0.544932</td>\n",
              "      <td>-0.494456</td>\n",
              "      <td>-0.270654</td>\n",
              "      <td>-0.400747</td>\n",
              "      <td>0.176600</td>\n",
              "      <td>0.223801</td>\n",
              "      <td>0.203298</td>\n",
              "      <td>-0.050269</td>\n",
              "      <td>0.085700</td>\n",
              "      <td>-0.058046</td>\n",
              "      <td>-0.077706</td>\n",
              "      <td>-0.046865</td>\n",
              "      <td>-0.018369</td>\n",
              "      <td>-0.502629</td>\n",
              "      <td>0.365745</td>\n",
              "      <td>0.356377</td>\n",
              "      <td>0.339491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Governor's School Enrollment</th>\n",
              "      <td>0.063664</td>\n",
              "      <td>-0.101744</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.015826</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>-0.030459</td>\n",
              "      <td>-0.028978</td>\n",
              "      <td>0.193902</td>\n",
              "      <td>0.221819</td>\n",
              "      <td>-0.037515</td>\n",
              "      <td>0.060574</td>\n",
              "      <td>0.255373</td>\n",
              "      <td>0.225747</td>\n",
              "      <td>0.254316</td>\n",
              "      <td>0.978020</td>\n",
              "      <td>-0.019597</td>\n",
              "      <td>-0.004847</td>\n",
              "      <td>-0.031320</td>\n",
              "      <td>-0.020942</td>\n",
              "      <td>-0.066583</td>\n",
              "      <td>0.264706</td>\n",
              "      <td>0.179295</td>\n",
              "      <td>0.173653</td>\n",
              "      <td>0.168013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Governor's STEM Academy</th>\n",
              "      <td>0.013693</td>\n",
              "      <td>-0.001687</td>\n",
              "      <td>-0.015826</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.035696</td>\n",
              "      <td>0.004476</td>\n",
              "      <td>-0.016388</td>\n",
              "      <td>0.090028</td>\n",
              "      <td>0.051701</td>\n",
              "      <td>0.008040</td>\n",
              "      <td>0.113395</td>\n",
              "      <td>0.179922</td>\n",
              "      <td>0.197221</td>\n",
              "      <td>0.194622</td>\n",
              "      <td>-0.028389</td>\n",
              "      <td>0.884189</td>\n",
              "      <td>-0.037949</td>\n",
              "      <td>-0.001682</td>\n",
              "      <td>-0.024251</td>\n",
              "      <td>-0.066468</td>\n",
              "      <td>0.060933</td>\n",
              "      <td>0.127719</td>\n",
              "      <td>0.109227</td>\n",
              "      <td>0.140677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Governor's Health Academy</th>\n",
              "      <td>0.020743</td>\n",
              "      <td>-0.061639</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>-0.035696</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.008871</td>\n",
              "      <td>-0.019607</td>\n",
              "      <td>0.085208</td>\n",
              "      <td>0.074239</td>\n",
              "      <td>0.091741</td>\n",
              "      <td>0.081037</td>\n",
              "      <td>0.183989</td>\n",
              "      <td>0.162986</td>\n",
              "      <td>0.183365</td>\n",
              "      <td>-0.014676</td>\n",
              "      <td>-0.039846</td>\n",
              "      <td>0.970964</td>\n",
              "      <td>-0.004365</td>\n",
              "      <td>-0.017242</td>\n",
              "      <td>-0.013487</td>\n",
              "      <td>0.088052</td>\n",
              "      <td>0.103413</td>\n",
              "      <td>0.106296</td>\n",
              "      <td>0.088001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Seniors Awarded IB Diplomas</th>\n",
              "      <td>0.033059</td>\n",
              "      <td>-0.083197</td>\n",
              "      <td>-0.030459</td>\n",
              "      <td>0.004476</td>\n",
              "      <td>-0.008871</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.910631</td>\n",
              "      <td>0.060446</td>\n",
              "      <td>0.081707</td>\n",
              "      <td>-0.112410</td>\n",
              "      <td>0.294250</td>\n",
              "      <td>-0.021381</td>\n",
              "      <td>-0.033345</td>\n",
              "      <td>-0.027137</td>\n",
              "      <td>-0.052367</td>\n",
              "      <td>-0.026776</td>\n",
              "      <td>-0.009372</td>\n",
              "      <td>0.937131</td>\n",
              "      <td>0.559823</td>\n",
              "      <td>-0.177699</td>\n",
              "      <td>0.034954</td>\n",
              "      <td>-0.097983</td>\n",
              "      <td>-0.102644</td>\n",
              "      <td>-0.080582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Senior IB Enrollment</th>\n",
              "      <td>0.049583</td>\n",
              "      <td>-0.086194</td>\n",
              "      <td>-0.028978</td>\n",
              "      <td>-0.016388</td>\n",
              "      <td>-0.019607</td>\n",
              "      <td>0.910631</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.050315</td>\n",
              "      <td>0.053966</td>\n",
              "      <td>-0.139510</td>\n",
              "      <td>0.271619</td>\n",
              "      <td>0.011515</td>\n",
              "      <td>0.006485</td>\n",
              "      <td>0.009973</td>\n",
              "      <td>-0.045800</td>\n",
              "      <td>-0.041717</td>\n",
              "      <td>-0.020696</td>\n",
              "      <td>0.860702</td>\n",
              "      <td>0.766099</td>\n",
              "      <td>-0.203909</td>\n",
              "      <td>0.017670</td>\n",
              "      <td>-0.068068</td>\n",
              "      <td>-0.076597</td>\n",
              "      <td>-0.048303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Students taking 1 or more AP Courses</th>\n",
              "      <td>0.243914</td>\n",
              "      <td>-0.544932</td>\n",
              "      <td>0.193902</td>\n",
              "      <td>0.090028</td>\n",
              "      <td>0.085208</td>\n",
              "      <td>0.060446</td>\n",
              "      <td>0.050315</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.915141</td>\n",
              "      <td>0.216485</td>\n",
              "      <td>0.776637</td>\n",
              "      <td>0.016428</td>\n",
              "      <td>-0.013131</td>\n",
              "      <td>0.005171</td>\n",
              "      <td>0.119882</td>\n",
              "      <td>-0.002577</td>\n",
              "      <td>0.075885</td>\n",
              "      <td>0.049947</td>\n",
              "      <td>0.017851</td>\n",
              "      <td>-0.248454</td>\n",
              "      <td>0.831751</td>\n",
              "      <td>-0.219375</td>\n",
              "      <td>-0.238288</td>\n",
              "      <td>-0.168119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Students taking 1 or more AP Exams</th>\n",
              "      <td>0.208914</td>\n",
              "      <td>-0.494456</td>\n",
              "      <td>0.221819</td>\n",
              "      <td>0.051701</td>\n",
              "      <td>0.074239</td>\n",
              "      <td>0.081707</td>\n",
              "      <td>0.053966</td>\n",
              "      <td>0.915141</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.207412</td>\n",
              "      <td>0.691103</td>\n",
              "      <td>-0.072431</td>\n",
              "      <td>-0.082646</td>\n",
              "      <td>-0.079664</td>\n",
              "      <td>0.158930</td>\n",
              "      <td>-0.018932</td>\n",
              "      <td>0.062885</td>\n",
              "      <td>0.061438</td>\n",
              "      <td>0.001655</td>\n",
              "      <td>-0.199424</td>\n",
              "      <td>0.907951</td>\n",
              "      <td>-0.247703</td>\n",
              "      <td>-0.266543</td>\n",
              "      <td>-0.193478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Students taking 1 or more Dual Enrollment Courses 1</th>\n",
              "      <td>0.165877</td>\n",
              "      <td>-0.270654</td>\n",
              "      <td>-0.037515</td>\n",
              "      <td>0.008040</td>\n",
              "      <td>0.091741</td>\n",
              "      <td>-0.112410</td>\n",
              "      <td>-0.139510</td>\n",
              "      <td>0.216485</td>\n",
              "      <td>0.207412</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.227624</td>\n",
              "      <td>-0.015736</td>\n",
              "      <td>-0.052400</td>\n",
              "      <td>-0.031244</td>\n",
              "      <td>-0.063233</td>\n",
              "      <td>-0.019094</td>\n",
              "      <td>0.061328</td>\n",
              "      <td>-0.122070</td>\n",
              "      <td>-0.136698</td>\n",
              "      <td>0.619964</td>\n",
              "      <td>0.203800</td>\n",
              "      <td>-0.138795</td>\n",
              "      <td>-0.134913</td>\n",
              "      <td>-0.129355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Student Count</th>\n",
              "      <td>0.108891</td>\n",
              "      <td>-0.400747</td>\n",
              "      <td>0.060574</td>\n",
              "      <td>0.113395</td>\n",
              "      <td>0.081037</td>\n",
              "      <td>0.294250</td>\n",
              "      <td>0.271619</td>\n",
              "      <td>0.776637</td>\n",
              "      <td>0.691103</td>\n",
              "      <td>0.227624</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.221607</td>\n",
              "      <td>0.136172</td>\n",
              "      <td>0.196532</td>\n",
              "      <td>-0.020332</td>\n",
              "      <td>-0.005883</td>\n",
              "      <td>0.063367</td>\n",
              "      <td>0.223951</td>\n",
              "      <td>0.100179</td>\n",
              "      <td>-0.323253</td>\n",
              "      <td>0.515138</td>\n",
              "      <td>-0.116835</td>\n",
              "      <td>-0.129609</td>\n",
              "      <td>-0.085619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOT_DAYSMISSED_M</th>\n",
              "      <td>-0.104200</td>\n",
              "      <td>0.176600</td>\n",
              "      <td>0.255373</td>\n",
              "      <td>0.179922</td>\n",
              "      <td>0.183989</td>\n",
              "      <td>-0.021381</td>\n",
              "      <td>0.011515</td>\n",
              "      <td>0.016428</td>\n",
              "      <td>-0.072431</td>\n",
              "      <td>-0.015736</td>\n",
              "      <td>0.221607</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.830708</td>\n",
              "      <td>0.974302</td>\n",
              "      <td>0.090067</td>\n",
              "      <td>0.129242</td>\n",
              "      <td>0.175258</td>\n",
              "      <td>-0.022053</td>\n",
              "      <td>-0.008827</td>\n",
              "      <td>-0.198555</td>\n",
              "      <td>-0.097332</td>\n",
              "      <td>0.817284</td>\n",
              "      <td>0.839877</td>\n",
              "      <td>0.695767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOT_DAYSMISSED_F</th>\n",
              "      <td>-0.103385</td>\n",
              "      <td>0.223801</td>\n",
              "      <td>0.225747</td>\n",
              "      <td>0.197221</td>\n",
              "      <td>0.162986</td>\n",
              "      <td>-0.033345</td>\n",
              "      <td>0.006485</td>\n",
              "      <td>-0.013131</td>\n",
              "      <td>-0.082646</td>\n",
              "      <td>-0.052400</td>\n",
              "      <td>0.136172</td>\n",
              "      <td>0.830708</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.934757</td>\n",
              "      <td>0.107403</td>\n",
              "      <td>0.167613</td>\n",
              "      <td>0.150698</td>\n",
              "      <td>-0.034078</td>\n",
              "      <td>-0.002447</td>\n",
              "      <td>-0.181408</td>\n",
              "      <td>-0.093789</td>\n",
              "      <td>0.857450</td>\n",
              "      <td>0.754381</td>\n",
              "      <td>0.913865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Days Missed</th>\n",
              "      <td>-0.108357</td>\n",
              "      <td>0.203298</td>\n",
              "      <td>0.254316</td>\n",
              "      <td>0.194622</td>\n",
              "      <td>0.183365</td>\n",
              "      <td>-0.027137</td>\n",
              "      <td>0.009973</td>\n",
              "      <td>0.005171</td>\n",
              "      <td>-0.079664</td>\n",
              "      <td>-0.031244</td>\n",
              "      <td>0.196532</td>\n",
              "      <td>0.974302</td>\n",
              "      <td>0.934757</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100947</td>\n",
              "      <td>0.150316</td>\n",
              "      <td>0.172834</td>\n",
              "      <td>-0.027866</td>\n",
              "      <td>-0.006624</td>\n",
              "      <td>-0.200131</td>\n",
              "      <td>-0.100072</td>\n",
              "      <td>0.868596</td>\n",
              "      <td>0.841295</td>\n",
              "      <td>0.813886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GovEnrPerStu</th>\n",
              "      <td>0.068458</td>\n",
              "      <td>-0.050269</td>\n",
              "      <td>0.978020</td>\n",
              "      <td>-0.028389</td>\n",
              "      <td>-0.014676</td>\n",
              "      <td>-0.052367</td>\n",
              "      <td>-0.045800</td>\n",
              "      <td>0.119882</td>\n",
              "      <td>0.158930</td>\n",
              "      <td>-0.063233</td>\n",
              "      <td>-0.020332</td>\n",
              "      <td>0.090067</td>\n",
              "      <td>0.107403</td>\n",
              "      <td>0.100947</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.015581</td>\n",
              "      <td>-0.018758</td>\n",
              "      <td>-0.053134</td>\n",
              "      <td>-0.025741</td>\n",
              "      <td>-0.040389</td>\n",
              "      <td>0.215993</td>\n",
              "      <td>0.189700</td>\n",
              "      <td>0.183015</td>\n",
              "      <td>0.178800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GovStemPerStu</th>\n",
              "      <td>0.008757</td>\n",
              "      <td>0.085700</td>\n",
              "      <td>-0.019597</td>\n",
              "      <td>0.884189</td>\n",
              "      <td>-0.039846</td>\n",
              "      <td>-0.026776</td>\n",
              "      <td>-0.041717</td>\n",
              "      <td>-0.002577</td>\n",
              "      <td>-0.018932</td>\n",
              "      <td>-0.019094</td>\n",
              "      <td>-0.005883</td>\n",
              "      <td>0.129242</td>\n",
              "      <td>0.167613</td>\n",
              "      <td>0.150316</td>\n",
              "      <td>-0.015581</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.041807</td>\n",
              "      <td>-0.030246</td>\n",
              "      <td>-0.039732</td>\n",
              "      <td>-0.008843</td>\n",
              "      <td>0.068078</td>\n",
              "      <td>0.120744</td>\n",
              "      <td>0.097703</td>\n",
              "      <td>0.141058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GovHeaPerStu</th>\n",
              "      <td>0.010755</td>\n",
              "      <td>-0.058046</td>\n",
              "      <td>-0.004847</td>\n",
              "      <td>-0.037949</td>\n",
              "      <td>0.970964</td>\n",
              "      <td>-0.009372</td>\n",
              "      <td>-0.020696</td>\n",
              "      <td>0.075885</td>\n",
              "      <td>0.062885</td>\n",
              "      <td>0.061328</td>\n",
              "      <td>0.063367</td>\n",
              "      <td>0.175258</td>\n",
              "      <td>0.150698</td>\n",
              "      <td>0.172834</td>\n",
              "      <td>-0.018758</td>\n",
              "      <td>-0.041807</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.004294</td>\n",
              "      <td>-0.017889</td>\n",
              "      <td>-0.025485</td>\n",
              "      <td>0.091584</td>\n",
              "      <td>0.099104</td>\n",
              "      <td>0.102904</td>\n",
              "      <td>0.082830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IBDipPerStu</th>\n",
              "      <td>0.035814</td>\n",
              "      <td>-0.077706</td>\n",
              "      <td>-0.031320</td>\n",
              "      <td>-0.001682</td>\n",
              "      <td>-0.004365</td>\n",
              "      <td>0.937131</td>\n",
              "      <td>0.860702</td>\n",
              "      <td>0.049947</td>\n",
              "      <td>0.061438</td>\n",
              "      <td>-0.122070</td>\n",
              "      <td>0.223951</td>\n",
              "      <td>-0.022053</td>\n",
              "      <td>-0.034078</td>\n",
              "      <td>-0.027866</td>\n",
              "      <td>-0.053134</td>\n",
              "      <td>-0.030246</td>\n",
              "      <td>-0.004294</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.622157</td>\n",
              "      <td>-0.174339</td>\n",
              "      <td>0.044450</td>\n",
              "      <td>-0.096144</td>\n",
              "      <td>-0.100528</td>\n",
              "      <td>-0.079346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IBEnrPerStu</th>\n",
              "      <td>0.067344</td>\n",
              "      <td>-0.046865</td>\n",
              "      <td>-0.020942</td>\n",
              "      <td>-0.024251</td>\n",
              "      <td>-0.017242</td>\n",
              "      <td>0.559823</td>\n",
              "      <td>0.766099</td>\n",
              "      <td>0.017851</td>\n",
              "      <td>0.001655</td>\n",
              "      <td>-0.136698</td>\n",
              "      <td>0.100179</td>\n",
              "      <td>-0.008827</td>\n",
              "      <td>-0.002447</td>\n",
              "      <td>-0.006624</td>\n",
              "      <td>-0.025741</td>\n",
              "      <td>-0.039732</td>\n",
              "      <td>-0.017889</td>\n",
              "      <td>0.622157</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.173479</td>\n",
              "      <td>0.008616</td>\n",
              "      <td>-0.057170</td>\n",
              "      <td>-0.069008</td>\n",
              "      <td>-0.033788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>APEnrPerStu</th>\n",
              "      <td>0.026790</td>\n",
              "      <td>-0.018369</td>\n",
              "      <td>-0.066583</td>\n",
              "      <td>-0.066468</td>\n",
              "      <td>-0.013487</td>\n",
              "      <td>-0.177699</td>\n",
              "      <td>-0.203909</td>\n",
              "      <td>-0.248454</td>\n",
              "      <td>-0.199424</td>\n",
              "      <td>0.619964</td>\n",
              "      <td>-0.323253</td>\n",
              "      <td>-0.198555</td>\n",
              "      <td>-0.181408</td>\n",
              "      <td>-0.200131</td>\n",
              "      <td>-0.040389</td>\n",
              "      <td>-0.008843</td>\n",
              "      <td>-0.025485</td>\n",
              "      <td>-0.174339</td>\n",
              "      <td>-0.173479</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.161967</td>\n",
              "      <td>-0.129094</td>\n",
              "      <td>-0.114877</td>\n",
              "      <td>-0.135700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>APExPerStu</th>\n",
              "      <td>0.257149</td>\n",
              "      <td>-0.502629</td>\n",
              "      <td>0.264706</td>\n",
              "      <td>0.060933</td>\n",
              "      <td>0.088052</td>\n",
              "      <td>0.034954</td>\n",
              "      <td>0.017670</td>\n",
              "      <td>0.831751</td>\n",
              "      <td>0.907951</td>\n",
              "      <td>0.203800</td>\n",
              "      <td>0.515138</td>\n",
              "      <td>-0.097332</td>\n",
              "      <td>-0.093789</td>\n",
              "      <td>-0.100072</td>\n",
              "      <td>0.215993</td>\n",
              "      <td>0.068078</td>\n",
              "      <td>0.091584</td>\n",
              "      <td>0.044450</td>\n",
              "      <td>0.008616</td>\n",
              "      <td>-0.161967</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.232991</td>\n",
              "      <td>-0.249741</td>\n",
              "      <td>-0.183393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TotalDaysMissedPerStu</th>\n",
              "      <td>-0.167456</td>\n",
              "      <td>0.365745</td>\n",
              "      <td>0.179295</td>\n",
              "      <td>0.127719</td>\n",
              "      <td>0.103413</td>\n",
              "      <td>-0.097983</td>\n",
              "      <td>-0.068068</td>\n",
              "      <td>-0.219375</td>\n",
              "      <td>-0.247703</td>\n",
              "      <td>-0.138795</td>\n",
              "      <td>-0.116835</td>\n",
              "      <td>0.817284</td>\n",
              "      <td>0.857450</td>\n",
              "      <td>0.868596</td>\n",
              "      <td>0.189700</td>\n",
              "      <td>0.120744</td>\n",
              "      <td>0.099104</td>\n",
              "      <td>-0.096144</td>\n",
              "      <td>-0.057170</td>\n",
              "      <td>-0.129094</td>\n",
              "      <td>-0.232991</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.969776</td>\n",
              "      <td>0.935262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MDaysMissedPerStu</th>\n",
              "      <td>-0.152500</td>\n",
              "      <td>0.356377</td>\n",
              "      <td>0.173653</td>\n",
              "      <td>0.109227</td>\n",
              "      <td>0.106296</td>\n",
              "      <td>-0.102644</td>\n",
              "      <td>-0.076597</td>\n",
              "      <td>-0.238288</td>\n",
              "      <td>-0.266543</td>\n",
              "      <td>-0.134913</td>\n",
              "      <td>-0.129609</td>\n",
              "      <td>0.839877</td>\n",
              "      <td>0.754381</td>\n",
              "      <td>0.841295</td>\n",
              "      <td>0.183015</td>\n",
              "      <td>0.097703</td>\n",
              "      <td>0.102904</td>\n",
              "      <td>-0.100528</td>\n",
              "      <td>-0.069008</td>\n",
              "      <td>-0.114877</td>\n",
              "      <td>-0.249741</td>\n",
              "      <td>0.969776</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.820632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FDaysMissedPerStu</th>\n",
              "      <td>-0.170833</td>\n",
              "      <td>0.339491</td>\n",
              "      <td>0.168013</td>\n",
              "      <td>0.140677</td>\n",
              "      <td>0.088001</td>\n",
              "      <td>-0.080582</td>\n",
              "      <td>-0.048303</td>\n",
              "      <td>-0.168119</td>\n",
              "      <td>-0.193478</td>\n",
              "      <td>-0.129355</td>\n",
              "      <td>-0.085619</td>\n",
              "      <td>0.695767</td>\n",
              "      <td>0.913865</td>\n",
              "      <td>0.813886</td>\n",
              "      <td>0.178800</td>\n",
              "      <td>0.141058</td>\n",
              "      <td>0.082830</td>\n",
              "      <td>-0.079346</td>\n",
              "      <td>-0.033788</td>\n",
              "      <td>-0.135700</td>\n",
              "      <td>-0.183393</td>\n",
              "      <td>0.935262</td>\n",
              "      <td>0.820632</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    4 Year Graduation Rate  ...  FDaysMissedPerStu\n",
              "4 Year Graduation Rate                                            1.000000  ...          -0.170833\n",
              "Free/Reduced Lunch %                                             -0.384786  ...           0.339491\n",
              "Governor's School Enrollment                                      0.063664  ...           0.168013\n",
              "Governor's STEM Academy                                           0.013693  ...           0.140677\n",
              "Governor's Health Academy                                         0.020743  ...           0.088001\n",
              "Seniors Awarded IB Diplomas                                       0.033059  ...          -0.080582\n",
              "Senior IB Enrollment                                              0.049583  ...          -0.048303\n",
              "Students taking 1 or more AP Courses                              0.243914  ...          -0.168119\n",
              "Students taking 1 or more AP Exams                                0.208914  ...          -0.193478\n",
              "Students taking 1 or more Dual Enrollment Cours...                0.165877  ...          -0.129355\n",
              "Student Count                                                     0.108891  ...          -0.085619\n",
              "TOT_DAYSMISSED_M                                                 -0.104200  ...           0.695767\n",
              "TOT_DAYSMISSED_F                                                 -0.103385  ...           0.913865\n",
              "Total Days Missed                                                -0.108357  ...           0.813886\n",
              "GovEnrPerStu                                                      0.068458  ...           0.178800\n",
              "GovStemPerStu                                                     0.008757  ...           0.141058\n",
              "GovHeaPerStu                                                      0.010755  ...           0.082830\n",
              "IBDipPerStu                                                       0.035814  ...          -0.079346\n",
              "IBEnrPerStu                                                       0.067344  ...          -0.033788\n",
              "APEnrPerStu                                                       0.026790  ...          -0.135700\n",
              "APExPerStu                                                        0.257149  ...          -0.183393\n",
              "TotalDaysMissedPerStu                                            -0.167456  ...           0.935262\n",
              "MDaysMissedPerStu                                                -0.152500  ...           0.820632\n",
              "FDaysMissedPerStu                                                -0.170833  ...           1.000000\n",
              "\n",
              "[24 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "y8kfnongFLMo",
        "outputId": "d82cb153-3df7-4b25-dc38-dea095ad481c"
      },
      "source": [
        "schooldata.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>4 Year Graduation Rate</th>\n",
              "      <th>Free/Reduced Lunch %</th>\n",
              "      <th>Governor's School Enrollment</th>\n",
              "      <th>Governor's STEM Academy</th>\n",
              "      <th>Governor's Health Academy</th>\n",
              "      <th>Seniors Awarded IB Diplomas</th>\n",
              "      <th>Senior IB Enrollment</th>\n",
              "      <th>Students taking 1 or more AP Courses</th>\n",
              "      <th>Students taking 1 or more AP Exams</th>\n",
              "      <th>Students taking 1 or more Dual Enrollment Courses 1</th>\n",
              "      <th>Student Count</th>\n",
              "      <th>TOT_DAYSMISSED_M</th>\n",
              "      <th>TOT_DAYSMISSED_F</th>\n",
              "      <th>Total Days Missed</th>\n",
              "      <th>GovEnrPerStu</th>\n",
              "      <th>GovStemPerStu</th>\n",
              "      <th>GovHeaPerStu</th>\n",
              "      <th>IBDipPerStu</th>\n",
              "      <th>IBEnrPerStu</th>\n",
              "      <th>APEnrPerStu</th>\n",
              "      <th>APExPerStu</th>\n",
              "      <th>TotalDaysMissedPerStu</th>\n",
              "      <th>MDaysMissedPerStu</th>\n",
              "      <th>FDaysMissedPerStu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>324.00000</td>\n",
              "      <td>329.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>327.000000</td>\n",
              "      <td>319.000000</td>\n",
              "      <td>319.000000</td>\n",
              "      <td>319.000000</td>\n",
              "      <td>327.000000</td>\n",
              "      <td>327.000000</td>\n",
              "      <td>327.000000</td>\n",
              "      <td>327.000000</td>\n",
              "      <td>327.000000</td>\n",
              "      <td>327.000000</td>\n",
              "      <td>327.000000</td>\n",
              "      <td>316.000000</td>\n",
              "      <td>316.000000</td>\n",
              "      <td>316.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>91.14071</td>\n",
              "      <td>43.744377</td>\n",
              "      <td>18.730303</td>\n",
              "      <td>9.496970</td>\n",
              "      <td>3.796970</td>\n",
              "      <td>3.303030</td>\n",
              "      <td>5.190909</td>\n",
              "      <td>264.066667</td>\n",
              "      <td>194.615152</td>\n",
              "      <td>102.621212</td>\n",
              "      <td>1210.926606</td>\n",
              "      <td>474.351097</td>\n",
              "      <td>224.545455</td>\n",
              "      <td>698.896552</td>\n",
              "      <td>0.016334</td>\n",
              "      <td>0.008012</td>\n",
              "      <td>0.002477</td>\n",
              "      <td>0.001779</td>\n",
              "      <td>0.003420</td>\n",
              "      <td>0.105946</td>\n",
              "      <td>0.121031</td>\n",
              "      <td>0.632319</td>\n",
              "      <td>0.429524</td>\n",
              "      <td>0.202795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.80770</td>\n",
              "      <td>23.465268</td>\n",
              "      <td>100.737840</td>\n",
              "      <td>34.920948</td>\n",
              "      <td>28.294339</td>\n",
              "      <td>14.006913</td>\n",
              "      <td>19.297776</td>\n",
              "      <td>294.691021</td>\n",
              "      <td>271.809070</td>\n",
              "      <td>102.755673</td>\n",
              "      <td>749.957754</td>\n",
              "      <td>620.995966</td>\n",
              "      <td>393.696660</td>\n",
              "      <td>973.048283</td>\n",
              "      <td>0.058691</td>\n",
              "      <td>0.026826</td>\n",
              "      <td>0.017578</td>\n",
              "      <td>0.007044</td>\n",
              "      <td>0.014653</td>\n",
              "      <td>0.103363</td>\n",
              "      <td>0.129398</td>\n",
              "      <td>0.773085</td>\n",
              "      <td>0.478841</td>\n",
              "      <td>0.330084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.19000</td>\n",
              "      <td>1.850000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>89.56750</td>\n",
              "      <td>28.030000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.250000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>559.000000</td>\n",
              "      <td>109.500000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>147.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022916</td>\n",
              "      <td>0.006100</td>\n",
              "      <td>0.143488</td>\n",
              "      <td>0.106804</td>\n",
              "      <td>0.033179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>93.21500</td>\n",
              "      <td>42.080000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>71.500000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>1135.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>320.000000</td>\n",
              "      <td>0.005848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.081035</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.389762</td>\n",
              "      <td>0.264540</td>\n",
              "      <td>0.096767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>95.46500</td>\n",
              "      <td>56.660000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>421.500000</td>\n",
              "      <td>273.500000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>1763.500000</td>\n",
              "      <td>528.000000</td>\n",
              "      <td>215.500000</td>\n",
              "      <td>786.500000</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.171036</td>\n",
              "      <td>0.192700</td>\n",
              "      <td>0.855975</td>\n",
              "      <td>0.547164</td>\n",
              "      <td>0.236564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.00000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1805.000000</td>\n",
              "      <td>316.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>1469.000000</td>\n",
              "      <td>1452.000000</td>\n",
              "      <td>489.000000</td>\n",
              "      <td>4300.000000</td>\n",
              "      <td>3483.000000</td>\n",
              "      <td>3914.000000</td>\n",
              "      <td>6723.000000</td>\n",
              "      <td>1.010638</td>\n",
              "      <td>0.252396</td>\n",
              "      <td>0.147997</td>\n",
              "      <td>0.060589</td>\n",
              "      <td>0.193452</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.744681</td>\n",
              "      <td>5.820430</td>\n",
              "      <td>3.319355</td>\n",
              "      <td>3.308538</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       4 Year Graduation Rate  ...  FDaysMissedPerStu\n",
              "count               324.00000  ...         316.000000\n",
              "mean                 91.14071  ...           0.202795\n",
              "std                   9.80770  ...           0.330084\n",
              "min                   3.19000  ...           0.000000\n",
              "25%                  89.56750  ...           0.033179\n",
              "50%                  93.21500  ...           0.096767\n",
              "75%                  95.46500  ...           0.236564\n",
              "max                 100.00000  ...           3.308538\n",
              "\n",
              "[8 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNaeUxUDTTyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c9e71f-7774-445d-e843-185d70601b2a"
      },
      "source": [
        "schooldata.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['4 Year Graduation Rate', 'Free/Reduced Lunch %',\n",
              "       'Governor's School Enrollment', 'Governor's STEM Academy',\n",
              "       'Governor's Health Academy', 'Seniors Awarded IB Diplomas',\n",
              "       'Senior IB Enrollment', 'Students taking 1 or more AP Courses',\n",
              "       'Students taking 1 or more AP Exams',\n",
              "       'Students taking 1 or more Dual Enrollment Courses 1', 'Student Count',\n",
              "       'TOT_DAYSMISSED_M', 'TOT_DAYSMISSED_F', 'Total Days Missed',\n",
              "       'GovEnrPerStu', 'GovStemPerStu', 'GovHeaPerStu', 'IBDipPerStu',\n",
              "       'IBEnrPerStu', 'APEnrPerStu', 'APExPerStu', 'TotalDaysMissedPerStu',\n",
              "       'MDaysMissedPerStu', 'FDaysMissedPerStu'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFCfBKNiHy2m"
      },
      "source": [
        "Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "29StjHTRhk9y",
        "outputId": "f49d062f-34b3-4e4b-f918-d65213641b68"
      },
      "source": [
        "schooldata=schooldata.dropna()\n",
        "sample_incomplete_rows = schooldata[schooldata.isnull().any(axis=1)].head()\n",
        "sample_incomplete_rows"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>4 Year Graduation Rate</th>\n",
              "      <th>Free/Reduced Lunch %</th>\n",
              "      <th>Governor's School Enrollment</th>\n",
              "      <th>Governor's STEM Academy</th>\n",
              "      <th>Governor's Health Academy</th>\n",
              "      <th>Seniors Awarded IB Diplomas</th>\n",
              "      <th>Senior IB Enrollment</th>\n",
              "      <th>Students taking 1 or more AP Courses</th>\n",
              "      <th>Students taking 1 or more AP Exams</th>\n",
              "      <th>Students taking 1 or more Dual Enrollment Courses 1</th>\n",
              "      <th>Student Count</th>\n",
              "      <th>TOT_DAYSMISSED_M</th>\n",
              "      <th>TOT_DAYSMISSED_F</th>\n",
              "      <th>Total Days Missed</th>\n",
              "      <th>GovEnrPerStu</th>\n",
              "      <th>GovStemPerStu</th>\n",
              "      <th>GovHeaPerStu</th>\n",
              "      <th>IBDipPerStu</th>\n",
              "      <th>IBEnrPerStu</th>\n",
              "      <th>APEnrPerStu</th>\n",
              "      <th>APExPerStu</th>\n",
              "      <th>TotalDaysMissedPerStu</th>\n",
              "      <th>MDaysMissedPerStu</th>\n",
              "      <th>FDaysMissedPerStu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [4 Year Graduation Rate, Free/Reduced Lunch %, Governor's School Enrollment, Governor's STEM Academy, Governor's Health Academy, Seniors Awarded IB Diplomas, Senior IB Enrollment, Students taking 1 or more AP Courses, Students taking 1 or more AP Exams, Students taking 1 or more Dual Enrollment Courses 1, Student Count, TOT_DAYSMISSED_M, TOT_DAYSMISSED_F, Total Days Missed, GovEnrPerStu, GovStemPerStu, GovHeaPerStu, IBDipPerStu, IBEnrPerStu, APEnrPerStu, APExPerStu, TotalDaysMissedPerStu, MDaysMissedPerStu, FDaysMissedPerStu]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6zyn1WZltWe"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#splitting data, 80/20\n",
        "train_set, test_set = train_test_split(schooldata, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z-4HgenHmmt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LByYMa0ol1Qo"
      },
      "source": [
        "#seperating training data and training labels\n",
        "schooldata = train_set.copy()\n",
        "schooldata = schooldata.drop(\"4 Year Graduation Rate\", axis=1) # drop labels for training set\n",
        "schooldata_labels = train_set[\"4 Year Graduation Rate\"].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLoNFRQhSMBI"
      },
      "source": [
        "Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCs7gI_zHdd7",
        "outputId": "8d768ca6-abda-44d0-8e67-c709462c1116"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, make_column_selector(dtype_include=np.number)),                         \n",
        "        (\"cat\", OneHotEncoder(), make_column_selector(dtype_include=object))\n",
        "    ])\n",
        "\n",
        "schooldata_prepared = full_pipeline.fit_transform(schooldata)\n",
        "schooldata_prepared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.94411179, -0.08332247, -0.31059438, ...,  0.52895074,\n",
              "        -0.01377499,  1.23101009],\n",
              "       [-0.30214863, -0.65237269, -0.31059438, ...,  0.00599109,\n",
              "         0.21183066, -0.28587069],\n",
              "       [ 0.1248154 , -0.65237269, -0.31059438, ..., -0.66756923,\n",
              "        -0.6858906 , -0.55896729],\n",
              "       ...,\n",
              "       [-0.87172297, -0.65237269, -0.31059438, ..., -0.50261839,\n",
              "        -0.44725868, -0.51865587],\n",
              "       [-0.7412497 ,  0.58056946,  2.55291257, ..., -0.57071637,\n",
              "        -0.617352  , -0.43406635],\n",
              "       [-0.01649452, -0.65237269, -0.31059438, ..., -0.42309832,\n",
              "        -0.41785181, -0.37811045]])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05I_7PIjnzcL"
      },
      "source": [
        "# Train Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We decided to start with three regression models. Those models are a linear regressor, a decision tree regressor, and a random forest regressor. "
      ],
      "metadata": {
        "id": "TuqEPIso91zL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb_jePran--2",
        "outputId": "023e9893-5654-4ee3-9f2c-1c35e56c90bd"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#create linear regression model\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(schooldata_prepared, schooldata_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nv_anN5oTi9",
        "outputId": "0b2e2ec9-27c4-4158-90f9-255669b3eb1a"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#linear regression preformance\n",
        "schooldata_predictions = lin_reg.predict(schooldata_prepared)\n",
        "lin_mse = mean_squared_error(schooldata_labels, schooldata_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "lin_rmse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.766073045359893"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6vH7Q4hoykv",
        "outputId": "85ff7076-ab96-4ff1-c98f-b2ec635c84ef"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "lin_mae = mean_absolute_error(schooldata_labels, schooldata_predictions)\n",
        "lin_mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.580215006736597"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm9xr_3vo8vw",
        "outputId": "d4f10592-7508-4a10-cc8f-b07eb5e1e608"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "#create decision tree model\n",
        "tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "tree_reg.fit(schooldata_prepared, schooldata_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFzKo0Y1pCtp",
        "outputId": "71bf0fcd-7fa2-48ef-8b04-5d574bb2b496"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#decision tree performance scores\n",
        "scores = cross_val_score(tree_reg, schooldata_prepared, schooldata_labels,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
        "tree_rmse_scores = np.sqrt(-scores)\n",
        "tree_rmse_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6.91353426,  5.60207105,  6.04771362,  5.20302643, 11.50205286,\n",
              "        4.02834557,  6.51574892,  3.87905272, 10.06675593,  4.30688499])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y24pzX_wpZEY",
        "outputId": "c22e9a4f-6640-420f-fd79-234eda48a98e"
      },
      "source": [
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())\n",
        "    print(\"Standard deviation:\", scores.std())\n",
        "\n",
        "display_scores(tree_rmse_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [ 6.91353426  5.60207105  6.04771362  5.20302643 11.50205286  4.02834557\n",
            "  6.51574892  3.87905272 10.06675593  4.30688499]\n",
            "Mean: 6.406518634356759\n",
            "Standard deviation: 2.414690978359954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-YMOGngpeGv",
        "outputId": "188e5bd7-c238-4bf5-a328-1cb069c3655c"
      },
      "source": [
        "lin_scores = cross_val_score(lin_reg, schooldata_prepared, schooldata_labels,\n",
        "                             scoring=\"neg_mean_squared_error\", cv=5)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [ 5.05911812  4.93904883 14.15827098  5.11652719  8.80811659]\n",
            "Mean: 7.616216339865415\n",
            "Standard deviation: 3.582555740410537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0hIOQsZpjzk",
        "outputId": "a2ec754c-4eb4-4d8e-91b5-51eed75c661c"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "#create random forest model\n",
        "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "forest_reg.fit(schooldata_prepared, schooldata_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v5MkLNrprA9",
        "outputId": "617c2715-f6cc-4963-8ea4-609891a5b171"
      },
      "source": [
        "#random forest performance scores\n",
        "schooldata_predictions = forest_reg.predict(schooldata_prepared)\n",
        "forest_mse = mean_squared_error(schooldata_labels, schooldata_predictions)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        "forest_rmse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.4580314678381594"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcvUoo4_pyfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969b1e93-761a-48ca-b046-a8fcb1e1475d"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "forest_scores = cross_val_score(forest_reg, schooldata_prepared, schooldata_labels,\n",
        "                                scoring=\"neg_mean_squared_error\", cv=5)\n",
        "forest_rmse_scores = np.sqrt(-forest_scores)\n",
        "display_scores(forest_rmse_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [4.50018694 5.3085807  8.59796567 4.24003137 7.94847487]\n",
            "Mean: 6.119047908324222\n",
            "Standard deviation: 1.805552952647295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxU1p5Ji0itV"
      },
      "source": [
        "# Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ5QMTHE0koo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1ec0a4d-baed-43e1-e48c-69e560771e9e"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#performing grid seach on decision tree\n",
        "grid_tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "tree_parameter_grid = [{'splitter': ['best', 'random'], 'max_features':[2, 4, 6, 8, 10, 12]}]\n",
        "tree_grid_search = GridSearchCV(grid_tree_reg, tree_parameter_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "tree_grid_search.fit(schooldata_prepared, schooldata_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(random_state=42),\n",
              "             param_grid=[{'max_features': [2, 4, 6, 8, 10, 12],\n",
              "                          'splitter': ['best', 'random']}],\n",
              "             return_train_score=True, scoring='neg_mean_squared_error')"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af10mjFN0mjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5336a8c0-ed22-4e8e-f324-62dab70d1259"
      },
      "source": [
        "tree_grid_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_features=8, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxkEXjqQ0orI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ca1850-2792-4b10-8488-f1f1451254bc"
      },
      "source": [
        "#performing grid seach on random forest\n",
        "grid_forest_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "forest_parameter_grid = [{'n_estimators':[10, 25, 50, 100], 'max_features':[2, 4, 6, 8, 10, 12]}]\n",
        "forest_grid_search = GridSearchCV(grid_forest_reg, forest_parameter_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "forest_grid_search.fit(schooldata_prepared, schooldata_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
              "             param_grid=[{'max_features': [2, 4, 6, 8, 10, 12],\n",
              "                          'n_estimators': [10, 25, 50, 100]}],\n",
              "             return_train_score=True, scoring='neg_mean_squared_error')"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_MDG0mm0rMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49ee4b5-9685-4072-8c40-d3a70886d1b5"
      },
      "source": [
        "forest_grid_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_features=12, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIcIhk7gsMnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4d35bb-0f40-4788-df7e-d3a1b6338818"
      },
      "source": [
        "grid_forest_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "forest_parameter_grid = [{'n_estimators':[5, 10, 15, 20], 'max_features':[8, 14, 16, 18, 20]}]\n",
        "forest_grid_search = GridSearchCV(grid_forest_reg, forest_parameter_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "forest_grid_search.fit(schooldata_prepared, schooldata_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
              "             param_grid=[{'max_features': [8, 14, 16, 18, 20],\n",
              "                          'n_estimators': [5, 10, 15, 20]}],\n",
              "             return_train_score=True, scoring='neg_mean_squared_error')"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3vPw6YpsNQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d44d65a-9c96-4c39-9db7-ba38925a132f"
      },
      "source": [
        "forest_grid_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_features=18, n_estimators=20, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxL0qfW10w7c"
      },
      "source": [
        "# Regression Model Test Scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the test scores below we can see that the random forest model (with the best hyperparameters as determined by the grid search) has the lowest RMSE. "
      ],
      "metadata": {
        "id": "vdYfa5sO9aLO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qxf8FPQ0tv2"
      },
      "source": [
        "school_test_data = test_set.copy()\n",
        "school_test_data = test_set.drop(\"4 Year Graduation Rate\", axis=1) # drop labels for training set\n",
        "school_test_labels = test_set[\"4 Year Graduation Rate\"].copy()\n",
        "\n",
        "school_test_prep = full_pipeline.transform(school_test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRQ2l8q22Jyw",
        "outputId": "9aa0ee61-5eb3-4d44-a893-831409d5079a"
      },
      "source": [
        "#final rmse value for linear regressor\n",
        "lin_test_pred = lin_reg.predict(school_test_prep)\n",
        "\n",
        "lin_test_mse = mean_squared_error(school_test_labels, lin_test_pred)\n",
        "lin_test_rmse = np.sqrt(lin_test_mse)\n",
        "print(lin_test_rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.78017537721665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRtoWPjcmysp",
        "outputId": "5c796a00-a400-4f58-aff2-f81fb36b24d1"
      },
      "source": [
        "print(schooldata.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Free/Reduced Lunch %', 'Governor's School Enrollment',\n",
            "       'Governor's STEM Academy', 'Governor's Health Academy',\n",
            "       'Seniors Awarded IB Diplomas', 'Senior IB Enrollment',\n",
            "       'Students taking 1 or more AP Courses',\n",
            "       'Students taking 1 or more AP Exams',\n",
            "       'Students taking 1 or more Dual Enrollment Courses 1', 'Student Count',\n",
            "       'TOT_DAYSMISSED_M', 'TOT_DAYSMISSED_F', 'Total Days Missed',\n",
            "       'GovEnrPerStu', 'GovStemPerStu', 'GovHeaPerStu', 'IBDipPerStu',\n",
            "       'IBEnrPerStu', 'APEnrPerStu', 'APExPerStu', 'TotalDaysMissedPerStu',\n",
            "       'MDaysMissedPerStu', 'FDaysMissedPerStu'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRIgUugLDZdT",
        "outputId": "505ca68e-bbe9-430f-e83e-268ee2c2f4b4"
      },
      "source": [
        "importance = lin_reg.coef_\n",
        "# summarize feature importance\n",
        "count = 0\n",
        "\n",
        "for i,v in enumerate(importance):\n",
        "  print(schooldata.columns[count])\n",
        "  print('Feature: ''%0d, Score: %.5f' % (i,v))\n",
        "  count+=1\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free/Reduced Lunch %\n",
            "Feature: 0, Score: -2.13222\n",
            "Governor's School Enrollment\n",
            "Feature: 1, Score: -1.95466\n",
            "Governor's STEM Academy\n",
            "Feature: 2, Score: -1.45263\n",
            "Governor's Health Academy\n",
            "Feature: 3, Score: 0.26990\n",
            "Seniors Awarded IB Diplomas\n",
            "Feature: 4, Score: 3.09241\n",
            "Senior IB Enrollment\n",
            "Feature: 5, Score: 0.10483\n",
            "Students taking 1 or more AP Courses\n",
            "Feature: 6, Score: 2.91942\n",
            "Students taking 1 or more AP Exams\n",
            "Feature: 7, Score: 0.40932\n",
            "Students taking 1 or more Dual Enrollment Courses 1\n",
            "Feature: 8, Score: 2.80669\n",
            "Student Count\n",
            "Feature: 9, Score: -3.95656\n",
            "TOT_DAYSMISSED_M\n",
            "Feature: 10, Score: -3.30208\n",
            "TOT_DAYSMISSED_F\n",
            "Feature: 11, Score: 6.73420\n",
            "Total Days Missed\n",
            "Feature: 12, Score: 0.78766\n",
            "GovEnrPerStu\n",
            "Feature: 13, Score: 2.39543\n",
            "GovStemPerStu\n",
            "Feature: 14, Score: 1.35576\n",
            "GovHeaPerStu\n",
            "Feature: 15, Score: -0.62114\n",
            "IBDipPerStu\n",
            "Feature: 16, Score: -2.72928\n",
            "IBEnrPerStu\n",
            "Feature: 17, Score: 0.43119\n",
            "APEnrPerStu\n",
            "Feature: 18, Score: -3.38444\n",
            "APExPerStu\n",
            "Feature: 19, Score: -1.21595\n",
            "TotalDaysMissedPerStu\n",
            "Feature: 20, Score: -1.12230\n",
            "MDaysMissedPerStu\n",
            "Feature: 21, Score: 3.05505\n",
            "FDaysMissedPerStu\n",
            "Feature: 22, Score: -6.89133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUWC3bRw0111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236164c5-f7cb-49b9-e719-6f5f502fe6dc"
      },
      "source": [
        "#final rmse value for decision tree \n",
        "tree_test_pred = tree_grid_search.best_estimator_.predict(school_test_prep)\n",
        "\n",
        "tree_test_mse = mean_squared_error(school_test_labels, tree_test_pred)\n",
        "tree_test_rmse = np.sqrt(tree_test_mse)\n",
        "print(tree_test_rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.8119080979916244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v0ReCKlFmny",
        "outputId": "f1fdfcf3-8731-48f3-ed21-b98b9af02466"
      },
      "source": [
        "importance = tree_reg.feature_importances_\n",
        "# summarize feature importance\n",
        "count = 0\n",
        "\n",
        "for i,v in enumerate(importance):\n",
        "  print(schooldata.columns[count])\n",
        "  print('Feature: ''%0d, Score: %.5f' % (i,v))\n",
        "  count+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free/Reduced Lunch %\n",
            "Feature: 0, Score: 0.21711\n",
            "Governor's School Enrollment\n",
            "Feature: 1, Score: 0.01922\n",
            "Governor's STEM Academy\n",
            "Feature: 2, Score: 0.00161\n",
            "Governor's Health Academy\n",
            "Feature: 3, Score: 0.00000\n",
            "Seniors Awarded IB Diplomas\n",
            "Feature: 4, Score: 0.00105\n",
            "Senior IB Enrollment\n",
            "Feature: 5, Score: 0.00000\n",
            "Students taking 1 or more AP Courses\n",
            "Feature: 6, Score: 0.01656\n",
            "Students taking 1 or more AP Exams\n",
            "Feature: 7, Score: 0.00904\n",
            "Students taking 1 or more Dual Enrollment Courses 1\n",
            "Feature: 8, Score: 0.01384\n",
            "Student Count\n",
            "Feature: 9, Score: 0.14119\n",
            "TOT_DAYSMISSED_M\n",
            "Feature: 10, Score: 0.00522\n",
            "TOT_DAYSMISSED_F\n",
            "Feature: 11, Score: 0.09520\n",
            "Total Days Missed\n",
            "Feature: 12, Score: 0.05457\n",
            "GovEnrPerStu\n",
            "Feature: 13, Score: 0.01676\n",
            "GovStemPerStu\n",
            "Feature: 14, Score: 0.00237\n",
            "GovHeaPerStu\n",
            "Feature: 15, Score: 0.00000\n",
            "IBDipPerStu\n",
            "Feature: 16, Score: 0.00178\n",
            "IBEnrPerStu\n",
            "Feature: 17, Score: 0.00000\n",
            "APEnrPerStu\n",
            "Feature: 18, Score: 0.25617\n",
            "APExPerStu\n",
            "Feature: 19, Score: 0.00746\n",
            "TotalDaysMissedPerStu\n",
            "Feature: 20, Score: 0.12137\n",
            "MDaysMissedPerStu\n",
            "Feature: 21, Score: 0.01173\n",
            "FDaysMissedPerStu\n",
            "Feature: 22, Score: 0.00775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG93ojGa1nxS",
        "outputId": "85532636-3942-4c11-fbc8-2d8aa9d46ffa"
      },
      "source": [
        "#final rmse value for random forest\n",
        "forest_test_pred = forest_grid_search.best_estimator_.predict(school_test_prep)\n",
        "\n",
        "forest_test_mse = mean_squared_error(school_test_labels, forest_test_pred)\n",
        "forest_test_rmse = np.sqrt(forest_test_mse)\n",
        "print(forest_test_rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.9451573581601522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9st9ucnzF7h8",
        "outputId": "04e9fe76-4a13-4738-c7ff-d44c3a6bb09f"
      },
      "source": [
        "importance = forest_reg.feature_importances_\n",
        "# summarize feature importance\n",
        "count = 0\n",
        "\n",
        "for i,v in enumerate(importance):\n",
        "  print(schooldata.columns[count])\n",
        "  print('Feature: ''%0d, Score: %.5f' % (i,v))\n",
        "  count+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free/Reduced Lunch %\n",
            "Feature: 0, Score: 0.23409\n",
            "Governor's School Enrollment\n",
            "Feature: 1, Score: 0.01399\n",
            "Governor's STEM Academy\n",
            "Feature: 2, Score: 0.00906\n",
            "Governor's Health Academy\n",
            "Feature: 3, Score: 0.00036\n",
            "Seniors Awarded IB Diplomas\n",
            "Feature: 4, Score: 0.00184\n",
            "Senior IB Enrollment\n",
            "Feature: 5, Score: 0.00096\n",
            "Students taking 1 or more AP Courses\n",
            "Feature: 6, Score: 0.02077\n",
            "Students taking 1 or more AP Exams\n",
            "Feature: 7, Score: 0.01050\n",
            "Students taking 1 or more Dual Enrollment Courses 1\n",
            "Feature: 8, Score: 0.03099\n",
            "Student Count\n",
            "Feature: 9, Score: 0.11489\n",
            "TOT_DAYSMISSED_M\n",
            "Feature: 10, Score: 0.03726\n",
            "TOT_DAYSMISSED_F\n",
            "Feature: 11, Score: 0.07737\n",
            "Total Days Missed\n",
            "Feature: 12, Score: 0.06653\n",
            "GovEnrPerStu\n",
            "Feature: 13, Score: 0.02663\n",
            "GovStemPerStu\n",
            "Feature: 14, Score: 0.00770\n",
            "GovHeaPerStu\n",
            "Feature: 15, Score: 0.00059\n",
            "IBDipPerStu\n",
            "Feature: 16, Score: 0.00103\n",
            "IBEnrPerStu\n",
            "Feature: 17, Score: 0.00108\n",
            "APEnrPerStu\n",
            "Feature: 18, Score: 0.21129\n",
            "APExPerStu\n",
            "Feature: 19, Score: 0.01391\n",
            "TotalDaysMissedPerStu\n",
            "Feature: 20, Score: 0.02432\n",
            "MDaysMissedPerStu\n",
            "Feature: 21, Score: 0.02086\n",
            "FDaysMissedPerStu\n",
            "Feature: 22, Score: 0.07398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu1diYWjwJfX"
      },
      "source": [
        "# Regression with Neural Nets\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Below are several neural networks. By experimenting with number of layers, nodes, per layer, learning rates for optimizers, etc, we are attempting to build a better performing model than the random forest model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0e0lVF7xs5X"
      },
      "source": [
        "X_train_split, X_valid_split  = train_test_split(train_set, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJQJF9-l2q6F"
      },
      "source": [
        "X_train = X_train_split.copy()\n",
        "X_train = X_train.drop(\"4 Year Graduation Rate\", axis=1) # drop labels for training set\n",
        "y_train = X_train_split[\"4 Year Graduation Rate\"].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j3NFgr_3BVT"
      },
      "source": [
        "X_valid = X_valid_split.copy()\n",
        "X_valid = X_valid_split.drop(\"4 Year Graduation Rate\", axis=1) # drop labels for training set\n",
        "y_valid = X_valid_split[\"4 Year Graduation Rate\"].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm3fsf0Tw0r8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "num_pipeline_neural = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "full_pipeline_neural = ColumnTransformer([\n",
        "        (\"num\", num_pipeline_neural, make_column_selector(dtype_include=np.number)),                         \n",
        "        (\"cat\", OneHotEncoder(), make_column_selector(dtype_include=object))\n",
        "    ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcpSYUiBzHrn"
      },
      "source": [
        "X_test = test_set.copy()\n",
        "X_test = X_test.drop(\"4 Year Graduation Rate\", axis=1) # drop labels for training set\n",
        "y_test = test_set[\"4 Year Graduation Rate\"].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cabWXHKOw5QP"
      },
      "source": [
        "X_train = full_pipeline_neural.fit_transform(X_train)\n",
        "X_valid = full_pipeline_neural.transform(X_valid)\n",
        "X_test = full_pipeline_neural.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Enf1bUWxbT2",
        "outputId": "9764324c-a73a-4178-dd48-984c3a2a5b24"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 8042.5029 - val_loss: 7073.9438\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6143.6299 - val_loss: 3894.0886\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2652.7410 - val_loss: 876.9382\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 615.3067 - val_loss: 248.7764\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 321.9312 - val_loss: 250.6626\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 213.7664 - val_loss: 226.7028\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 157.3197 - val_loss: 132.5522\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 126.4974 - val_loss: 168.5797\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 113.7515 - val_loss: 165.2755\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 105.7534 - val_loss: 148.9641\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 90.9516 - val_loss: 113.5204\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 84.1506 - val_loss: 127.8533\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 76.3598 - val_loss: 100.4489\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 71.5414 - val_loss: 122.2144\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 69.2640 - val_loss: 108.1553\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 64.9262 - val_loss: 87.8758\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 60.7170 - val_loss: 98.4599\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 60.3005 - val_loss: 103.8895\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 59.1109 - val_loss: 95.3370\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 55.7509 - val_loss: 97.2282\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 70.2411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itGSZjjL6lao",
        "outputId": "d2fab230-64d7-4b68-a0ba-3a7a1ee177d1"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 70.2411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70.24114990234375"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TS9eMJm7jNt",
        "outputId": "39f5cfaf-e1d1-447e-fae3-b47edafca18d"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.380999337927653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPKOLNxe7W3d",
        "outputId": "43930e5d-956b-4b0c-9fc7-634fd72dabbe"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(20, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 8219.0566 - val_loss: 7525.1001\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6572.3022 - val_loss: 4402.7632\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2793.0391 - val_loss: 776.9647\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 532.0493 - val_loss: 249.3533\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 264.8586 - val_loss: 289.6454\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 175.9291 - val_loss: 269.1967\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 132.8482 - val_loss: 199.8831\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 113.0013 - val_loss: 252.0337\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 105.0322 - val_loss: 228.1090\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 95.6182 - val_loss: 217.9178\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 86.1060 - val_loss: 201.4146\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 79.9670 - val_loss: 188.9977\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 73.2609 - val_loss: 155.3992\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 68.8063 - val_loss: 164.8941\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 64.3976 - val_loss: 153.7258\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 61.7713 - val_loss: 134.4696\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 58.9039 - val_loss: 141.5644\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 58.8829 - val_loss: 130.8614\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 56.2594 - val_loss: 122.8833\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 53.6042 - val_loss: 125.9668\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 131.1438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LLZhBVr6rQP",
        "outputId": "b6b00003-882b-4ace-fe40-8a2a82a5c229"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.451805298925239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sMV_6cooStU",
        "outputId": "45ddb759-0fc8-4034-d470-0a2e2368e485"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(20, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 7775.4858 - val_loss: 7082.5015\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6601.6758 - val_loss: 5884.9390\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5397.3276 - val_loss: 4652.5200\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4179.2124 - val_loss: 3470.7097\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3062.8892 - val_loss: 2455.3906\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2128.3679 - val_loss: 1672.7711\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1433.8324 - val_loss: 1108.0663\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 945.6381 - val_loss: 722.2703\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 617.5372 - val_loss: 469.2072\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 406.5988 - val_loss: 307.2926\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 272.6852 - val_loss: 205.5093\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 189.3935 - val_loss: 142.2651\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 137.9710 - val_loss: 102.4787\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 105.5581 - val_loss: 78.0652\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 85.7606 - val_loss: 63.0019\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 73.4135 - val_loss: 53.4746\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 65.6367 - val_loss: 47.4961\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 60.6396 - val_loss: 43.5559\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 57.2545 - val_loss: 40.9802\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 55.1376 - val_loss: 39.2926\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 53.9095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHpMwzv6oTMN",
        "outputId": "90fb63b3-2599-4702-db80-8bd3b3f567a3"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.342309688794263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBslH4L7BTM7",
        "outputId": "850ca766-b65b-42eb-a0c7-a1fd46786cc2"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(25, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(10, activation=\"sigmoid\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 8049.7310 - val_loss: 7472.3140\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6935.6357 - val_loss: 6153.8579\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5584.8730 - val_loss: 4818.2793\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4338.4976 - val_loss: 3709.4858\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3337.6582 - val_loss: 2850.4797\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2568.1826 - val_loss: 2193.7170\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1980.0699 - val_loss: 1688.7655\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1528.4745 - val_loss: 1301.3864\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1182.5284 - val_loss: 1004.7132\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 917.9357 - val_loss: 777.5737\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 715.6230 - val_loss: 603.2589\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 560.6925 - val_loss: 470.0753\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 442.4106 - val_loss: 367.3035\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 351.4211 - val_loss: 288.8157\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 282.0911 - val_loss: 228.4188\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 228.8321 - val_loss: 181.7623\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 187.8595 - val_loss: 146.0526\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 156.6483 - val_loss: 118.5997\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 132.7148 - val_loss: 97.6012\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 114.5059 - val_loss: 81.2781\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 77.2975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY4VkRr9BeZn",
        "outputId": "85a37953-b146-4554-bcb4-adef2f6813a8"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.791899715667347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv8KN-BYBipE",
        "outputId": "e59a4cd3-7f11-485e-e586-756d1ddd6f74"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(25, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(10, activation=\"sigmoid\"),\n",
        "    keras.layers.Dense(5, activation=\"sigmoid\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 8313.1533 - val_loss: 8084.2876\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7837.3647 - val_loss: 7522.7031\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7227.6670 - val_loss: 6841.9014\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6519.1069 - val_loss: 6098.6860\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5776.0527 - val_loss: 5358.4839\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5050.7607 - val_loss: 4655.4219\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4380.8174 - val_loss: 4031.4375\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3794.8982 - val_loss: 3491.9067\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3288.7471 - val_loss: 3025.9065\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2851.6372 - val_loss: 2623.2390\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2474.0010 - val_loss: 2274.7891\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2147.4146 - val_loss: 1973.7905\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1865.2878 - val_loss: 1712.6542\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1620.7781 - val_loss: 1487.0958\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1409.6621 - val_loss: 1291.6764\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1226.8168 - val_loss: 1122.1522\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1068.3718 - val_loss: 975.6031\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 931.5107 - val_loss: 848.7016\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 813.0939 - val_loss: 738.9899\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 710.7702 - val_loss: 643.7057\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 616.7700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LhUlWLyBskd",
        "outputId": "c8907997-71a6-4911-e8bf-cf7777af5056"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24.83485493276033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcqgSh14CHtu",
        "outputId": "c7590167-8d9a-40fd-ed6f-1fd997bbdb64"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(25, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 7856.1650 - val_loss: 7045.6440\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6495.2451 - val_loss: 5690.2749\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5154.2393 - val_loss: 4343.3901\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3843.7979 - val_loss: 3096.2246\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2686.6287 - val_loss: 2067.0601\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1760.6007 - val_loss: 1314.8168\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1107.4321 - val_loss: 806.5182\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 678.0465 - val_loss: 484.6121\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 411.2172 - val_loss: 293.3254\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 254.7507 - val_loss: 181.2480\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 164.8583 - val_loss: 116.1866\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 113.9039 - val_loss: 78.9495\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 85.2240 - val_loss: 56.9878\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 68.7255 - val_loss: 44.2824\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 59.4664 - val_loss: 36.9193\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 54.1097 - val_loss: 32.4129\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 50.8862 - val_loss: 29.5895\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 48.8068 - val_loss: 27.6470\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 47.3717 - val_loss: 26.3887\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 46.5092 - val_loss: 25.4858\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.7802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL9L--acCISE",
        "outputId": "c398e590-38a8-41da-e2cf-2de0141f63d9"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.270694635348069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6OXHRPiCPIq",
        "outputId": "2e84137c-524d-4549-8e4c-428082160144"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(50, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(25, activation=\"sigmoid\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 29ms/step - loss: 7808.2681 - val_loss: 6551.3267\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5611.0962 - val_loss: 4331.6890\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3569.9622 - val_loss: 2579.4761\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2061.9504 - val_loss: 1416.6818\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1128.5376 - val_loss: 765.9957\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 621.8104 - val_loss: 421.6732\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 354.8487 - val_loss: 237.0048\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 212.6949 - val_loss: 138.4928\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 137.5800 - val_loss: 86.2964\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.1885 - val_loss: 58.5743\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 77.6478 - val_loss: 43.5887\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 66.7127 - val_loss: 35.7272\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 61.1271 - val_loss: 31.1875\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 58.0097 - val_loss: 28.7943\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 56.4663 - val_loss: 27.4001\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 55.5834 - val_loss: 26.5245\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 55.0935 - val_loss: 26.0279\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 54.9044 - val_loss: 25.7218\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 54.6565 - val_loss: 25.5505\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 54.6239 - val_loss: 25.3997\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 30.1978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JRyBVdnCWPY",
        "outputId": "717dcf57-48a3-446f-f5c0-4318916f3625"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.495250905689338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nykv8LXmCcz1",
        "outputId": "8f086e90-9cc1-4642-f49f-9a97165069ee"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(50, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(25, activation=\"sigmoid\"),\n",
        "    keras.layers.Dense(5, activation=\"sigmoid\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 8173.5493 - val_loss: 7729.4414\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7393.5088 - val_loss: 6957.1704\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6613.1133 - val_loss: 6179.7671\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5868.4912 - val_loss: 5480.7007\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5205.2749 - val_loss: 4861.6748\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4617.8428 - val_loss: 4312.4868\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4095.3328 - val_loss: 3819.2571\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3620.9648 - val_loss: 3358.6526\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3167.8184 - val_loss: 2915.5261\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2747.8875 - val_loss: 2527.0247\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2383.8279 - val_loss: 2191.3774\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2069.3379 - val_loss: 1901.5834\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1797.7510 - val_loss: 1650.1808\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1562.3824 - val_loss: 1433.0381\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1359.1677 - val_loss: 1244.9031\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1183.1592 - val_loss: 1081.6848\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1030.6301 - val_loss: 940.5851\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 898.8790 - val_loss: 818.3969\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 784.8801 - val_loss: 712.7592\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 686.3745 - val_loss: 621.0044\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 594.6693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6DD8e6VCh5b",
        "outputId": "36d3242c-2d1e-4396-be57-e3f66a2345ae"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24.385842440306167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y5sW6wZCq65",
        "outputId": "fd48432f-7764-46af-a976-6cd8771234bc"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(50, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(25, activation=\"sigmoid\"),\n",
        "    keras.layers.Dense(10, activation=\"sigmoid\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 8032.8286 - val_loss: 7360.4072\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6760.9565 - val_loss: 5923.3389\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5368.6807 - val_loss: 4655.2344\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4219.0718 - val_loss: 3658.1958\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3318.5696 - val_loss: 2878.1243\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2613.8083 - val_loss: 2266.3367\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2060.1296 - val_loss: 1781.1696\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1619.5632 - val_loss: 1391.7178\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1264.4635 - val_loss: 1077.7578\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 981.9944 - val_loss: 833.3978\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 764.3649 - val_loss: 645.9152\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 597.8425 - val_loss: 502.7846\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 470.7900 - val_loss: 392.4230\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 373.1163 - val_loss: 308.1534\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 298.7016 - val_loss: 243.3288\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 241.5501 - val_loss: 193.2717\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 197.5955 - val_loss: 154.9524\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 164.1046 - val_loss: 125.4973\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 138.4285 - val_loss: 102.9647\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 118.8882 - val_loss: 85.4570\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 81.0609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqKHzMkECwnk",
        "outputId": "fc4ddce3-d64d-4b6a-e1cf-287460e7140d"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.003381305874191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVCfmrbgCz3r",
        "outputId": "10936c66-1dc2-409a-a80e-30b6c1063940"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(50, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(25, activation=\"sigmoid\"),\n",
        "    keras.layers.Dense(15, activation=\"sigmoid\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 31ms/step - loss: 8008.1602 - val_loss: 7318.6289\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6675.9556 - val_loss: 5712.8379\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5020.1992 - val_loss: 4090.9778\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3547.5378 - val_loss: 2850.4626\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2472.5085 - val_loss: 1986.4784\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1729.8540 - val_loss: 1391.0422\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1217.5034 - val_loss: 976.0697\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 861.0145 - val_loss: 687.3487\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 613.5772 - val_loss: 486.9264\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 442.2242 - val_loss: 347.7990\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 323.6189 - val_loss: 250.8313\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 241.2870 - val_loss: 183.7411\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 184.4636 - val_loss: 136.4770\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 144.6924 - val_loss: 103.8001\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 117.3704 - val_loss: 80.8710\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.2803 - val_loss: 64.6407\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 84.9107 - val_loss: 53.3573\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 75.7596 - val_loss: 45.4458\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 69.3507 - val_loss: 39.9626\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 65.0180 - val_loss: 36.0013\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 37.6492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP605BOHC2Az",
        "outputId": "e1a90ccb-9308-46b9-bf2a-068de662f3a0"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.135895361195864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcTGl-n2C9A3",
        "outputId": "5fe96c72-c7ae-4d13-be09-f157a1bbeae1"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(50, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(25, activation=\"sigmoid\"),\n",
        "    keras.layers.Dense(20, activation=\"sigmoid\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 31ms/step - loss: 7924.1309 - val_loss: 6967.2227\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6151.4155 - val_loss: 4945.3936\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4136.7153 - val_loss: 3076.2756\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2526.4990 - val_loss: 1847.2307\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1525.3837 - val_loss: 1116.9204\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 932.5171 - val_loss: 683.3229\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 580.3548 - val_loss: 421.6925\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 368.6563 - val_loss: 264.3088\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 241.9960 - val_loss: 170.0610\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 166.5724 - val_loss: 113.5813\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 121.7453 - val_loss: 79.4175\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 94.8792 - val_loss: 59.0891\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 79.0516 - val_loss: 46.4266\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 69.3625 - val_loss: 38.9007\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 63.7396 - val_loss: 34.2350\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 60.2988 - val_loss: 31.2552\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 58.1933 - val_loss: 29.4476\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 57.0272 - val_loss: 28.3237\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 56.2250 - val_loss: 27.6542\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 55.8568 - val_loss: 27.1813\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 31.6226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyUfgTuCDA7X",
        "outputId": "8fd67679-c6f5-4d87-bc62-bc6f115a4d3c"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.623401838668098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXaJsiopDKds",
        "outputId": "6d183532-9e54-433c-cc49-9940aa5e31be"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(50, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(30, activation=\"sigmoid\"),#25\n",
        "    keras.layers.Dense(15, activation=\"sigmoid\"),#30\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-2))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3648.9163 - val_loss: 197.3054\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 107.3702 - val_loss: 28.7998\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 57.3532 - val_loss: 26.8305\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 55.5413 - val_loss: 26.4434\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 56.9263 - val_loss: 26.7069\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 56.0475 - val_loss: 28.0679\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 55.9101 - val_loss: 26.7124\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 55.6902 - val_loss: 26.3523\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 55.7282 - val_loss: 26.3833\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 55.3848 - val_loss: 26.4322\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 55.9901 - val_loss: 26.3479\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 55.4961 - val_loss: 26.6492\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 55.7411 - val_loss: 26.3340\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 55.6945 - val_loss: 26.5178\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 55.7273 - val_loss: 26.3978\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 55.5618 - val_loss: 26.3439\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 55.7771 - val_loss: 26.3544\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 56.3805 - val_loss: 26.3390\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 55.5112 - val_loss: 26.3241\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 55.7005 - val_loss: 26.3609\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 32.4174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABy_cyqcDQ-t",
        "outputId": "c982d298-874c-4bea-c72f-20b5147bac6b"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.693632068941109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDZlUA5J85RS"
      },
      "source": [
        "Wide and Deep Models\n",
        "\n",
        "\n",
        "---\n",
        "These neural networks ended up performing the best of the neural nets, but we were not able to create one that performs better than the random forest\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVHXEtUUpI5D"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn75cEv853yb"
      },
      "source": [
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(25, activation=\"relu\")(input_)\n",
        "hidden2 = keras.layers.Dense(5, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_], outputs=[output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLIuU40Q7gQS",
        "outputId": "61dc095e-dfcd-414c-9c1a-5946407e15fa"
      },
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 31ms/step - loss: 8073.9790 - val_loss: 5491.0532\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2768.3716 - val_loss: 1661.4017\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1443.4622 - val_loss: 846.3315\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 927.8328 - val_loss: 437.0363\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 205.7502 - val_loss: 373.7504\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 162.4500 - val_loss: 662.9015\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 590.1021 - val_loss: 907.3448\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 594.4255 - val_loss: 733.0149\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 547.4547 - val_loss: 421.6791\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 441.1928 - val_loss: 408.0062\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 387.2851 - val_loss: 422.1360\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 159.3955 - val_loss: 165.4230\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 88.2774 - val_loss: 310.0373\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 161.5163 - val_loss: 314.5607\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 168.3513 - val_loss: 308.7456\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 154.4615 - val_loss: 122.2095\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 301.7391 - val_loss: 772.6072\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 618.7371 - val_loss: 116.5912\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 89.6339 - val_loss: 132.3578\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.0727 - val_loss: 285.7135\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 281.8212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LMJlvS77vO9",
        "outputId": "0eab08b6-84b3-4595-c656-b1a1d45c47ff"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16.787531012920443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd2lybJZM-c5"
      },
      "source": [
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(50, activation=\"relu\")(input_)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "hidden3 = keras.layers.Dense(15, activation=\"relu\")(hidden2)\n",
        "concat = keras.layers.concatenate([input_, hidden3])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_], outputs=[output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NigtaMxCNH9b",
        "outputId": "4bad660e-8e21-476d-d3b3-58e8d8514856"
      },
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 31ms/step - loss: 7766.6846 - val_loss: 3190.6868\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6741.5244 - val_loss: 2734.5056\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7452.0171 - val_loss: 8026.6914\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7052.3418 - val_loss: 12975.0547\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7577.1104 - val_loss: 7775.5254\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7593.9072 - val_loss: 7361.9209\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6325.4702 - val_loss: 7421.5630\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7090.7900 - val_loss: 5860.3296\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4517.2856 - val_loss: 8007.0947\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6929.8960 - val_loss: 7415.0376\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6881.8608 - val_loss: 4581.2710\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7228.5054 - val_loss: 6783.8760\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6668.8208 - val_loss: 6582.8867\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6496.0420 - val_loss: 6424.6538\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6337.7725 - val_loss: 6274.7329\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6190.9556 - val_loss: 6128.2876\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6043.6860 - val_loss: 5983.7178\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5901.9116 - val_loss: 5843.5332\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5760.3682 - val_loss: 5705.1523\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5624.6699 - val_loss: 5570.5103\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5512.6270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcufTXbsNJh3",
        "outputId": "746694bc-8fca-42c9-a7b7-4437049cec1e"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74.24706696648023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2TxxeCHNYO0"
      },
      "source": [
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(50, activation=\"sigmoid\")(input_)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"sigmoid\")(hidden1)\n",
        "hidden3 = keras.layers.Dense(15, activation=\"sigmoid\")(hidden2)\n",
        "concat = keras.layers.concatenate([input_, hidden3])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_], outputs=[output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR3ymRYnNdFy",
        "outputId": "37b73b2b-55da-43a6-aee2-de73e3ac7fe6"
      },
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 34ms/step - loss: 8014.2026 - val_loss: 7223.9023\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6463.8677 - val_loss: 5364.3530\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4646.6821 - val_loss: 3714.2776\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3185.3281 - val_loss: 2521.1135\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2168.4153 - val_loss: 1716.9504\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1482.8982 - val_loss: 1175.4834\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1021.6962 - val_loss: 806.3429\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 708.2498 - val_loss: 555.5491\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 495.7117 - val_loss: 385.6580\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 352.1065 - val_loss: 270.3080\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 254.9380 - val_loss: 191.7017\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 189.1291 - val_loss: 138.6600\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 144.9173 - val_loss: 102.0577\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 114.6359 - val_loss: 77.2450\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 94.2327 - val_loss: 60.1655\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 80.3341 - val_loss: 48.2819\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 70.7872 - val_loss: 40.1584\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 64.3533 - val_loss: 34.5044\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 59.9014 - val_loss: 30.6330\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 56.9473 - val_loss: 27.8609\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 29.9133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyeHq3fvNetW",
        "outputId": "239cd96e-5663-44e8-ade1-4199085b0f7e"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.4693050429829055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpr9w-7wN_pH"
      },
      "source": [
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(50, activation=\"sigmoid\")(input_)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"sigmoid\")(hidden1)\n",
        "hidden3 = keras.layers.Dense(15, activation=\"sigmoid\")(hidden2)\n",
        "concat = keras.layers.concatenate([input_, hidden3])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_], outputs=[output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnXwt-uuOBsG",
        "outputId": "3fddb82d-e485-4347-9c94-ca6d30f06669"
      },
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 36ms/step - loss: 8150.5117 - val_loss: 7510.8071\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6855.0688 - val_loss: 5762.7983\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4992.1333 - val_loss: 3943.6304\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3391.1919 - val_loss: 2667.5298\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2305.2048 - val_loss: 1813.2435\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1575.1132 - val_loss: 1238.9171\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1084.2926 - val_loss: 847.8407\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 750.8079 - val_loss: 582.4649\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 524.7184 - val_loss: 402.8100\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 371.9322 - val_loss: 281.0324\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 268.5386 - val_loss: 198.1932\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 198.5645 - val_loss: 142.4535\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 151.5454 - val_loss: 104.0107\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 119.2908 - val_loss: 78.0523\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 97.5755 - val_loss: 60.2264\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 82.7695 - val_loss: 47.8795\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 72.6026 - val_loss: 39.4964\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 65.7641 - val_loss: 33.6927\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 61.0146 - val_loss: 29.7630\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 57.8675 - val_loss: 26.9553\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 55.7211 - val_loss: 25.0635\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 54.1872 - val_loss: 23.7024\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 53.1174 - val_loss: 22.7787\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 52.4282 - val_loss: 22.1431\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 51.8661 - val_loss: 21.6234\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 51.4796 - val_loss: 21.2242\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 51.1677 - val_loss: 20.9001\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 50.9725 - val_loss: 20.6576\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 50.7336 - val_loss: 20.4864\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 50.6179 - val_loss: 20.3787\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 25.4299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYuZBcydOC70",
        "outputId": "a9a277ab-49bc-4426-d3d0-11d6b623e3ef"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.042805545686493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeAIRRf8OW49"
      },
      "source": [
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(50, activation=\"sigmoid\")(input_)\n",
        "hidden2 = keras.layers.Dense(40, activation=\"sigmoid\")(hidden1)\n",
        "hidden3 = keras.layers.Dense(30, activation=\"sigmoid\")(hidden2)\n",
        "hidden4 = keras.layers.Dense(15, activation=\"sigmoid\")(hidden3)\n",
        "concat = keras.layers.concatenate([input_, hidden4])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_], outputs=[output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arz3MTgIOZHY",
        "outputId": "89d0bd71-98df-46bc-878c-d73237c8d566"
      },
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-2))\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 38ms/step - loss: 3971.3054 - val_loss: 243.3371\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 117.7464 - val_loss: 27.3925\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 52.9784 - val_loss: 21.7807\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 50.0179 - val_loss: 20.1971\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 50.4594 - val_loss: 20.2103\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 49.4619 - val_loss: 21.1851\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 48.7918 - val_loss: 19.4839\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 47.9112 - val_loss: 19.1891\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 48.0685 - val_loss: 18.9696\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 47.3731 - val_loss: 18.5459\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 47.6276 - val_loss: 18.2108\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 46.9205 - val_loss: 18.9969\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 46.6087 - val_loss: 18.5134\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 46.2526 - val_loss: 18.4073\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 46.4378 - val_loss: 18.1370\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 45.8853 - val_loss: 18.0007\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 46.1033 - val_loss: 17.8788\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 46.0248 - val_loss: 17.6282\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 45.4526 - val_loss: 17.5660\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 45.2917 - val_loss: 17.5268\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 45.9470 - val_loss: 17.4429\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 45.3236 - val_loss: 17.6892\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 45.0249 - val_loss: 17.9125\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 45.2265 - val_loss: 18.3294\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 44.8211 - val_loss: 17.7251\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 44.7296 - val_loss: 17.5803\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 44.5824 - val_loss: 17.4819\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 45.1810 - val_loss: 17.4121\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 44.8914 - val_loss: 17.5578\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 44.7056 - val_loss: 18.0011\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.8707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al2fP1oGOb-c",
        "outputId": "3c2f22a9-9a22-4797-f6c4-dd44103cba8e"
      },
      "source": [
        "rmse_test = np.sqrt(mse_test)\n",
        "print(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.885761999791181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.title('Best Performing Neural Network Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "dQxqaAG9EJ0I",
        "outputId": "6efd7a2b-38f3-4533-ba62-35f0a9acdffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hr-BmAt_djG"
      },
      "source": [
        "# Ensemble Learning\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "By using a voting regressor that averages the predictions of the three original regression models, it should perform better than the best regressor (random forest)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogPEX0cQDvht"
      },
      "source": [
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "linear_reg = LinearRegression()\n",
        "decision_tree_reg = DecisionTreeRegressor(max_features = 8, random_state=42)\n",
        "random_forest_reg = RandomForestRegressor(max_features = 18, n_estimators = 20, random_state=42)\n",
        "\n",
        "voting_reg = VotingRegressor(\n",
        "    estimators=[('lr', linear_reg), ('rf', random_forest_reg), ('dt', decision_tree_reg)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MziZB3JCWbbt",
        "outputId": "0ab7caa2-2a53-40b9-e6e2-7c6b8394869b"
      },
      "source": [
        "voting_reg.fit(schooldata_prepared, schooldata_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingRegressor(estimators=[('lr', LinearRegression()),\n",
              "                            ('rf',\n",
              "                             RandomForestRegressor(max_features=18,\n",
              "                                                   n_estimators=20,\n",
              "                                                   random_state=42)),\n",
              "                            ('dt',\n",
              "                             DecisionTreeRegressor(max_features=8,\n",
              "                                                   random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6KaGZCxWlRt",
        "outputId": "90792c93-cc89-4cab-8780-55c4e5db54aa"
      },
      "source": [
        "voting_pred = voting_reg.predict(school_test_prep)\n",
        "\n",
        "voting_mse = mean_squared_error(school_test_labels, voting_pred)\n",
        "voting_rmse = np.sqrt(voting_mse)\n",
        "print(voting_rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.810679638697147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This performs better than random forest! But maybe by having the random forest predictions weigh more, the voting regressor will end up with an even lower RMSE."
      ],
      "metadata": {
        "id": "8dATgGUN2Uy3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocotxwOOYias"
      },
      "source": [
        "linear_reg = LinearRegression()\n",
        "decision_tree_reg = DecisionTreeRegressor(max_features = 8, random_state=42)\n",
        "random_forest_reg = RandomForestRegressor(max_features = 18, n_estimators = 20, random_state=42)\n",
        "\n",
        "voting_reg_weight = VotingRegressor(\n",
        "    estimators=[('lr', linear_reg), ('rf', random_forest_reg), ('dt', decision_tree_reg)], \n",
        "    weights=[0.25, 0.5, 0.25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxcUgVukYnDC",
        "outputId": "79963ea0-7362-4649-8890-ad64c956f4a1"
      },
      "source": [
        "voting_reg_weight.fit(schooldata_prepared, schooldata_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingRegressor(estimators=[('lr', LinearRegression()),\n",
              "                            ('rf',\n",
              "                             RandomForestRegressor(max_features=18,\n",
              "                                                   n_estimators=20,\n",
              "                                                   random_state=42)),\n",
              "                            ('dt',\n",
              "                             DecisionTreeRegressor(max_features=8,\n",
              "                                                   random_state=42))],\n",
              "                weights=[0.25, 0.5, 0.25])"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYLMFARIYonv",
        "outputId": "e88d08cc-a4a9-402e-b399-dca98dfe6f78"
      },
      "source": [
        "voting_weight_pred = voting_reg_weight.predict(school_test_prep)\n",
        "\n",
        "voting_weight_mse = mean_squared_error(school_test_labels, voting_weight_pred)\n",
        "voting_weight_rmse = np.sqrt(voting_weight_mse)\n",
        "print(voting_weight_rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7048572081176405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po1hRWJ-6v95"
      },
      "source": [
        "linear_reg = LinearRegression()\n",
        "decision_tree_reg = DecisionTreeRegressor(max_features = 8, random_state=42)\n",
        "random_forest_reg = RandomForestRegressor(max_features = 18, n_estimators = 20, random_state=42)\n",
        "\n",
        "voting_reg_weight = VotingRegressor(\n",
        "    estimators=[('lr', linear_reg), ('rf', random_forest_reg), ('dt', decision_tree_reg)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8XZ3kj07GCw",
        "outputId": "838916ad-0132-473d-d35d-aa2589637b80"
      },
      "source": [
        "vote_param_grid = [{'weights': [None, [0.25, 0.5, 0.25], [0, 0.7, 0.3], [0.3, 0.7, 0], [0.3, 0.5, 0.2], [0.2, 0.5, 0.3]]}]\n",
        "vote_grid_search = GridSearchCV(voting_reg_weight, vote_param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "vote_grid_search.fit(schooldata_prepared, schooldata_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=VotingRegressor(estimators=[('lr', LinearRegression()),\n",
              "                                                   ('rf',\n",
              "                                                    RandomForestRegressor(max_features=18,\n",
              "                                                                          n_estimators=20,\n",
              "                                                                          random_state=42)),\n",
              "                                                   ('dt',\n",
              "                                                    DecisionTreeRegressor(max_features=8,\n",
              "                                                                          random_state=42))]),\n",
              "             param_grid=[{'weights': [None, [0.25, 0.5, 0.25], [0, 0.7, 0.3],\n",
              "                                      [0.3, 0.7, 0], [0.3, 0.5, 0.2],\n",
              "                                      [0.2, 0.5, 0.3]]}],\n",
              "             return_train_score=True, scoring='neg_mean_squared_error')"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcHtRXpH7y-B",
        "outputId": "6e321454-75b9-40e3-8b57-01a17718a287"
      },
      "source": [
        "vote_grid_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingRegressor(estimators=[('lr', LinearRegression()),\n",
              "                            ('rf',\n",
              "                             RandomForestRegressor(max_features=18,\n",
              "                                                   n_estimators=20,\n",
              "                                                   random_state=42)),\n",
              "                            ('dt',\n",
              "                             DecisionTreeRegressor(max_features=8,\n",
              "                                                   random_state=42))],\n",
              "                weights=[0, 0.7, 0.3])"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCSMV5Nl8wIT"
      },
      "source": [
        "voting_weight_pred = vote_grid_search.best_estimator_.predict(school_test_prep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S39KGUt85HX",
        "outputId": "09cea91c-4184-483b-c2a7-93954e4fdf18"
      },
      "source": [
        "voting_weight_mse = mean_squared_error(school_test_labels, voting_weight_pred)\n",
        "voting_weight_rmse = np.sqrt(voting_weight_mse)\n",
        "print(voting_weight_rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8173514387300287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy-aDWQkOWF-"
      },
      "source": [
        "# Analysis and Experimentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the best performing model. It is a voting regressor with a 50% weight assigned to random forest predictions, and 25% each assigned to the linear regressor and the decision tree models."
      ],
      "metadata": {
        "id": "pPleOSVw2uP7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XD8Pn8GFerM"
      },
      "source": [
        "linear_reg = LinearRegression()\n",
        "decision_tree_reg = DecisionTreeRegressor(max_features = 8, random_state=42)\n",
        "random_forest_reg = RandomForestRegressor(max_features = 18, n_estimators = 20, random_state=42)\n",
        "\n",
        "voting_reg_weight = VotingRegressor(\n",
        "    estimators=[('lr', linear_reg), ('rf', random_forest_reg), ('dt', decision_tree_reg)], \n",
        "    weights=[0.25, 0.5, 0.25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "earVw29FFhmS",
        "outputId": "74d49d73-5ec0-437a-b264-1ee313e822bd"
      },
      "source": [
        "voting_reg_weight.fit(schooldata_prepared, schooldata_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingRegressor(estimators=[('lr', LinearRegression()),\n",
              "                            ('rf',\n",
              "                             RandomForestRegressor(max_features=18,\n",
              "                                                   n_estimators=20,\n",
              "                                                   random_state=42)),\n",
              "                            ('dt',\n",
              "                             DecisionTreeRegressor(max_features=8,\n",
              "                                                   random_state=42))],\n",
              "                weights=[0.25, 0.5, 0.25])"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEsp6RoTFkJj",
        "outputId": "6864ffae-9a92-4171-f676-5e2dd899dd07"
      },
      "source": [
        "voting_weight_pred = voting_reg_weight.predict(school_test_prep)\n",
        "\n",
        "voting_weight_mse = mean_squared_error(school_test_labels, voting_weight_pred)\n",
        "voting_weight_rmse = np.sqrt(voting_weight_mse)\n",
        "print(voting_weight_rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7048572081176405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The feature with the highest importance score is free and reduced lunch rate (based on the random forest model). We are taking the first datapoint in the normalized testing data and seeing how the voting regressor's prediction changes when it is given a lower value (-1) and a higher value (1). This is when compared by the model's prediction before the datapoint was altered (94.28834055). From the code below, it seems that having a low f/r rate led to a higher predition (by about .02%). However, by having a high f/r rate, the prediction lowers (by about 4%)! "
      ],
      "metadata": {
        "id": "AE8JepYZ3g9C"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4K8S3_6E6H1",
        "outputId": "a0148054-33a5-486c-e2ed-83eb9635255d"
      },
      "source": [
        "schooldata_sample = schooldata_prepared[:1].copy()\n",
        "schooldata_sample_label = schooldata_labels[:1].copy()\n",
        "schooldata_sample_pred = voting_reg_weight.predict(schooldata_sample)\n",
        "\n",
        "print(schooldata_sample_label)\n",
        "print(schooldata_sample_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135    94.21\n",
            "Name: 4 Year Graduation Rate, dtype: float64\n",
            "[94.28834055]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(schooldata_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9Np14hIA7vD",
        "outputId": "3ccd4938-bf8d-40d3-9368-9e6c755611a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.94411179 -0.08332247 -0.31059438 -0.11294795  0.75432322  3.22483053\n",
            "   0.17054327 -0.13087699 -0.72835361  0.25039737  0.20848017  1.5838963\n",
            "   0.79767673 -0.23487818 -0.33661891 -0.12268749  1.23310777  2.990771\n",
            "  -0.83328704 -0.06363432  0.52895074 -0.01377499  1.23101009]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTxt_IPLH9Ne"
      },
      "source": [
        "schooldata_sample[:1, 0] = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbNYZukbICqr",
        "outputId": "62a70f58-6170-42a2-e1bc-0060f2e98892"
      },
      "source": [
        "print(schooldata_sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.         -0.08332247 -0.31059438 -0.11294795  0.75432322  3.22483053\n",
            "   0.17054327 -0.13087699 -0.72835361  0.25039737  0.20848017  1.5838963\n",
            "   0.79767673 -0.23487818 -0.33661891 -0.12268749  1.23310777  2.990771\n",
            "  -0.83328704 -0.06363432  0.52895074 -0.01377499  1.23101009]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t9mhZQTIKvX"
      },
      "source": [
        "schooldata_sample_pred = voting_reg_weight.predict(schooldata_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MpXGFARIMo9",
        "outputId": "84930646-7833-4d64-d336-c103bcb8d4d1"
      },
      "source": [
        "print(schooldata_sample_label)\n",
        "print(schooldata_sample_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135    94.21\n",
            "Name: 4 Year Graduation Rate, dtype: float64\n",
            "[94.30988205]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx-KIrhdIPJG"
      },
      "source": [
        "schooldata_sample[:1, 0] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90nXwsIeISSi"
      },
      "source": [
        "schooldata_sample_pred = voting_reg_weight.predict(schooldata_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwcLA1yZITYI",
        "outputId": "09c91275-9bcd-4a1e-9281-6cb5e97253db"
      },
      "source": [
        "print(schooldata_sample_label)\n",
        "print(schooldata_sample_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135    94.21\n",
            "Name: 4 Year Graduation Rate, dtype: float64\n",
            "[90.88377173]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVn_6fhvLPEa"
      },
      "source": [
        "schooldata_sample = schooldata_prepared[:1].copy() #getting first data point again"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another feature with a comparitavely high importance score is the percentage of students enrolled in at least one AP class. We are taking the first datapoint in the normalized testing data and seeing how the voting regressor's prediction changes when it is given a lower value (-1) and a higher value (1). These new predictions are compared to the model's prediction before the datapoint was altered (94.28834055). From the code below, it seems that having a low AP enrollment rate led to a lower predition. However, having a high AP enrollment rate also led to a lower prediction. Both predictions were around 1% lower than the first prediction. "
      ],
      "metadata": {
        "id": "xF0hRpvI7HLT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1RZnmUaM7Lm"
      },
      "source": [
        "schooldata_sample_pred = voting_reg_weight.predict(schooldata_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0aLLlEwM9Xx",
        "outputId": "622061e5-cf4e-4921-bd7a-fc327f87459c"
      },
      "source": [
        "print(schooldata_sample_label)\n",
        "print(schooldata_sample_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135    94.21\n",
            "Name: 4 Year Graduation Rate, dtype: float64\n",
            "[94.28834055]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxsnJIL5JH1r"
      },
      "source": [
        "schooldata_sample[:1, 18] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6zQUz0aLaGT"
      },
      "source": [
        "schooldata_sample_pred = voting_reg_weight.predict(schooldata_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RCew6MSLcYt",
        "outputId": "ea7e0dcb-d400-4f32-9838-a5d98a8faacd"
      },
      "source": [
        "print(schooldata_sample_label)\n",
        "print(schooldata_sample_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135    94.21\n",
            "Name: 4 Year Graduation Rate, dtype: float64\n",
            "[93.09667899]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAQMdnrVLwUz"
      },
      "source": [
        "schooldata_sample[:1, 18] = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6QTGauYLxYN"
      },
      "source": [
        "schooldata_sample_pred = voting_reg_weight.predict(schooldata_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey4-n_35Lzcg",
        "outputId": "6c707cd9-eb80-4768-96ef-f0659e2c3703"
      },
      "source": [
        "print(schooldata_sample_label)\n",
        "print(schooldata_sample_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135    94.21\n",
            "Name: 4 Year Graduation Rate, dtype: float64\n",
            "[93.56239797]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xt = school_test_prep[:62]\n",
        "\n",
        "pred1 = lin_reg.predict(xt)\n",
        "pred2 = tree_reg.predict(xt)\n",
        "pred3 = forest_reg.predict(xt)\n",
        "pred4 = voting_reg_weight.predict(xt)"
      ],
      "metadata": {
        "id": "6BRQvwnrTQjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(pred1, \"gd\", label=\"LinearRegression\")\n",
        "plt.plot(pred2, \"b^\", label=\"DecisionRegressor\")\n",
        "plt.plot(pred3, \"ys\", label=\"RandomForestRegression\")\n",
        "plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n",
        "\n",
        "\n",
        "\n",
        "plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
        "plt.ylabel(\"predicted\")\n",
        "plt.xlabel(\"training samples\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.title(\"Regressor predictions and their average\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "oRB5svC-T4Oo",
        "outputId": "2443950b-4dee-4165-a3dd-654c82f81f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "---\n",
        "\n",
        "*   https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html - Help with merging dataframes.\n",
        "*   https://colab.research.google.com/drive/10VjV1l6ZWsmmwc34hffV62_lSRfx5neQ - Help with feature engineering, hyperparamter tuning, training regressor models.\n",
        "*   https://colab.research.google.com/drive/1x5biI3dP5YvvDEI0wapJcSgQNnATDzNe - Examples of neural nets used for regression.\n",
        "*   https://colab.research.google.com/drive/1fhUB6bKPe43UfYvEQ3b98KwLWo5qEPlc - Example voting regressors."
      ],
      "metadata": {
        "id": "iZCRunDoIUQM"
      }
    }
  ]
}